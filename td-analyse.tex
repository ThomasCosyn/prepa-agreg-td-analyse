\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{enumitem}
\usepackage{geometry}
\usepackage{graphicx}
\geometry{a4paper, margin=1.5cm}


\title{\Large \textbf{TD Analyse}}
\author{Thomas Goossaert-Cosyn}

\newtheoremstyle{exercisestyle}
{}                % Espace avant
{}                % Espace après
{\normalfont}  % Police du titre (gras)
{}                % Indentation
{\bfseries}       % Police du titre de l'énoncé (gras)
{.}               % Ponctuation après le titre
{ }               % Espace après le titre
{}                % Style du corps (par défaut)
\theoremstyle{exercisestyle}
\newtheorem{exercise}{Exercice}

% Alignement des puces à gauche et espacement réduit
\setlist[itemize]{leftmargin=*, itemsep=0.3em}

\let\oldsection\section
\renewcommand{\section}{\clearpage\oldsection}



\begin{document}
	\maketitle
	
	\section{Suites et séries}
	
	\setcounter{exercise}{8}
	\begin{exercise}{(Recherche d’équivalent)}
		On se donne $u_0 > 0$ et on construit par récurrence la suite $u_{n+1}=u_n+\frac{1}{u_n}$ pour $n \geq 0$. Donner un équivalent à la suite $u_n$.
	\end{exercise}
	
	\begin{proof}
		Par une récurrence immédiate on voit que $\forall n\in\mathbb{N}, u_n>0$.\\
		Ainsi on a une suite définie par récurrence $u_{n+1}=f(u_n)$ pour la fonction $f\mapsto x+\frac{1}{x}$ qui est continue sur $\mathbb{R}^*_+$ et au-dessus de l'identité. Donc $(u_n)_n$ est croissante.\\
		Soit elle diverge vers $+\infty$, soit elle converge vers une limite $l$ solution de :
		\[l=l+\frac{1}{l}\]
		Cela n'est pas possible donc $u_n \rightarrow +\infty$ \\
		Pour trouver un équivalent, calculons :
		\[u_{n+1}^{2}=u_n^{2}+2+\frac{1}{u_n^{2}}\]
		On a donc :
		\[u_{n+1}^{2}-u_{n}^{2} \sim 2\]
		Par le théorème de Césaro :
		\[\frac{1}{n}\sum_{k=0}^n(u_{k+1}^{2}-u_k^{2}) \sim 2\]
		Et par télescopage :
		\[u_n^{2}\sim 2n\]
		Conclusion :
		\[u_n^{2}\sim \sqrt{2n}\]
	\end{proof}
	
	\setcounter{exercise}{23}
	\begin{exercise}
		Soit $u = (u_n)_{n \ge 1}$ une suite de nombres réels ou complexes, non nuls. On lui associe la suite des produits partiels $(p_n)_{n \ge 1}$ définie pour $n \ge 1$ par $p_n = \prod_{k=1}^n u_k$. On dira que le produit infini de terme général $u_n$ (ou de manière abrégée $\prod u_n$) converge lorsque la suite $(p_n)$ admet une limite \textbf{finie non nulle}.
		
		\begin{enumerate}
			\item Montrer que si le produit infini $\prod u_n$ converge, alors la suite $(u_n)$ converge vers $1$. Étudier la réciproque en simplifiant $\prod_{k=1}^n \left(1 + \frac{1}{k}\right)$.
			\item Soit $z$ un nombre complexe tel que $|z| < 1$.
			\begin{enumerate}
				\item Calculer $(1 - z^2) \prod_{k=1}^n (1 + z^{2^k})$.
				\item En déduire que le produit infini $\prod (1 + z^{2^n})$ converge et donner la valeur du produit.
			\end{enumerate}
			\item On suppose $u = (u_n)_{n \ge 1}$ est une suite réelle avec $u_n > 0$ pour tout $n$. Montrer que le produit infini $\prod u_n$ converge si et seulement si la série $\sum \log u_n$ converge.
			\item On suppose $u = (u_n)_{n \ge 1}$ est une suite qui converge vers $1$ avec $u_n > 1$ pour tout $n$. Montrer que le produit infini $\prod u_n$ converge si et seulement si la série $\sum (u_n - 1)$ converge.
		\end{enumerate}
	\end{exercise}
	
	\begin{proof}
		\begin{enumerate}
			\item
			\begin{itemize}
				\item Si $\prod u_n$ converge, alors $p_n \to L \in \mathbb{C}^*$. Pour $n > 1$, on a $u_n = \frac{p_n}{p_{n-1}}$. Par passage à la limite, $u_n \to \frac{L}{L} = 1$.
				\item Soit $u_n = 1 + \frac{1}{n}$. On a bien $u_n \to 1$. Cependant par télescopage :
				\[ p_n = \prod_{k=1}^n \frac{k+1}{k} = \frac{2}{1} \cdot \frac{3}{2} \cdots \frac{n+1}{n} = n+1 \]
				Comme $p_n \to +\infty$, le produit infini diverge. La réciproque est donc fausse.
			\end{itemize}
			
			\item
			\begin{enumerate}
				\item Notons $P_n = (1 - z^2) \prod_{k=1}^n (1 + z^{2^k})$. Par récurrence :
				Pour $n=1$, $(1-z^2)(1+z^2) = 1-z^4 = 1-z^{2^2}$.
				En supposant $P_n = 1-z^{2^{n+1}}$, on a $P_{n+1} = P_n(1+z^{2^{n+1}}) = (1-z^{2^{n+1}})(1+z^{2^{n+1}}) = 1-(z^{2^{n+1}})^2 = 1-z^{2^{n+2}}$.
				L'expression vaut donc $1 - z^{2^{n+1}}$.
				\item Comme $|z| < 1$, $z^{2^{n+1}} \to 0$ quand $n \to \infty$. Ainsi $P_n \to 1$. Le produit infini converge vers $\frac{1}{1-z^2}$.
			\end{enumerate}
			
			\item Posons $S_n = \sum_{k=1}^n \log u_k$. On a $p_n = \prod_{k=1}^n u_k = \exp(S_n)$. 
			Par continuité de l'exponentielle et du logarithme sur $\mathbb{R}_+^*$, $(p_n)$ converge vers $L > 0$ si et seulement si $(S_n)$ converge vers $\log L$.
			
			\item Posons $a_n = u_n - 1 > 0$. On a $u_n \to 1 \implies a_n \to 0$. 
			D'après la question précédente, le produit converge ssi $\sum \log(1+a_n)$ converge.
			Or, au voisinage de $0$, $\log(1+a_n) \sim a_n$. Comme ce sont des séries à termes positifs, par théorème de comparaison, elles sont de même nature. Ainsi, $\prod u_n$ converge ssi $\sum (u_n - 1)$ converge.
		\end{enumerate}
	\end{proof}
	
	\section{Fonctions d'une variable réelle}
	
	\setcounter{exercise}{23}
	\begin{exercise}
		Soit $f$ une fonction réelle définie sur un intervalle ouvert $I$. On suppose que pour tout $x \in I$ on a
		\[
		\liminf_{h \to 0^+} \frac{f(x+h) + f(x-h) - 2f(x)}{2h} > 0.
		\]
		Montrer que $f$ est convexe sur $I$.
		
		Le résultat reste vrai si on suppose seulement que la $\liminf$ est $\geq 0$. Voyez-vous comment faire ?
	\end{exercise}
	
	\begin{proof}
		Posons les fonctions pentes
		\[s_+(x,h)=\frac{f(x+h)-f(x)}{h}, s_-(x,h)=\frac{f(x)-f(x-h)}{h}\]
		L'hypothèse de l'énoncé se réécrit alors
		\[\forall x\in I, \liminf_{h\rightarrow 0^{+}} s_+(x,h)-s_-(x,h) > 0\]
		Pour passer de cette propriété locale à une inégalité globale, considérons $[a,c]\subset I$ et $[x_0=a,...,x_n=c]$ une subdivision de pas $\Delta=\frac{c-a}{n}$.\\
		On définit la suite de pentes locales par :
		\[s_k=\frac{f(x_{k+1})-f(x_k)}{\Delta}\]
		L'hypothèse donne don que $s_0<s_1<...<s_{n-1}$\\
		Soit $b\in [a,c]$, $n$ suffisamment grand et $k$ tel que $x_k\leq b<x_{k+1}$, alors la croissance des pentes entraine
		\[\frac{f(b)-f(a)}{b-a}\leq s_k<\frac{f(c)-f(b)}{c-b}\]
		D'où la convexité de $f$.
	\end{proof}
	
	\section{Analyse complexe}
	
	\setcounter{exercise}{10}
	\begin{exercise}
		\begin{enumerate}
			\item Soit $\varphi$ une fonction holomorphe sur un ouvert $U$ de $\mathbb{C}$. On peut la voir comme une application de $U \subset \mathbb{R}^2$ vers $\mathbb{R}^2$. Montrer que son déterminant jacobien au point $z$ vaut $|\varphi'(z)|^2$.
			\item Soit $D = \{z \in \mathbb{C} \mid |z| < 1\}$. Vérifier que la formule $\varphi(z) = \frac{2z - i}{iz + 2}$ définit une bijection holomorphe de $D$ sur $D$.
			\item Utiliser la formule de changement de variables pour en déduire la valeur de l'intégrale 
			\[ I = \iint_D \frac{dxdy}{(x^2 + (y - 2)^2)^2}. \]
		\end{enumerate}
	\end{exercise}
	
	\begin{proof}
		\begin{enumerate}
			\item Déterminant Jacobien :
			Posons $z = x + iy$ et $\varphi(z) = u(x,y) + iv(x,y)$. La matrice jacobienne de $\varphi$ vue comme application de $\mathbb{R}^2$ est :
			\[ J_\varphi(z) = \begin{pmatrix} \frac{\partial u}{\partial x} & \frac{\partial u}{\partial y} \\ \frac{\partial v}{\partial x} & \frac{\partial v}{\partial y} \end{pmatrix} \]
			Comme $\varphi$ est holomorphe, elle vérifie les conditions de Cauchy-Riemann : $\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y}$ et $\frac{\partial u}{\partial y} = -\frac{\partial v}{\partial x}$. Le déterminant vaut donc :
			\[ \det(J_\varphi(z)) = \frac{\partial u}{\partial x} \frac{\partial v}{\partial y} - \frac{\partial u}{\partial y} \frac{\partial v}{\partial x} = \left(\frac{\partial u}{\partial x}\right)^2 + \left(\frac{\partial v}{\partial x}\right)^2 \]
			Or, par définition de la dérivée complexe, $\varphi'(z) = \frac{\partial u}{\partial x} + i \frac{\partial v}{\partial x}$. Ainsi, $|\varphi'(z)|^2 = \left(\frac{\partial u}{\partial x}\right)^2 + \left(\frac{\partial v}{\partial x}\right)^2$. On a bien $\det(J_\varphi(z)) = |\varphi'(z)|^2$.
			
			\item Bijection de $D$ sur $D$ :
			$\varphi$ est holomorphe sur $\mathbb{C} \setminus \{2i\}$. Comme $2i \notin D$, $\varphi$ est holomorphe sur $D$. \\
			Son inverse est donnée par $\varphi^{-1}(z)=\frac{2z+i}{2-iz}$ \\
			Pour le bord $|z|=1$, on calcule $|\varphi(z)|^2 = \frac{|2z-i|^2}{|iz+2|^2}$.
			\[ |2z-i|^2 = (2z-i)(2\bar{z}+i) = 4|z|^2 + 2zi - 2\bar{z}i + 1 = 5 + 2i(z-\bar{z}) \]
			\[ |iz+2|^2 = (iz+2)(-i\bar{z}+2) = |z|^2 + 2iz - 2i\bar{z} + 4 = 5 + 2i(z-\bar{z}) \]
			Ainsi, si $|z|=1$, alors $|\varphi(z)|=1$. Par le principe du maximum (et comme $\varphi(i/2)=0$), $\varphi$ envoie $D$ dans $D$. C'est une bijection car par les mêmes arguments, son inverse est envoie également $D$ sur $D$.
			
			\item Calcul de l'intégrale :
			Remarquons que $|iz+2|^2 = |i(z - 2i)|^2 = |z-2i|^2 = x^2 + (y-2)^2$. L'intégrande est donc $\frac{1}{|iz+2|^4}$.
			Calculons la dérivée : $\varphi'(z) = \frac{2(iz+2) - i(2z-i)}{(iz+2)^2} = \frac{2iz+4-2iz+i^2}{(iz+2)^2} = \frac{3}{(iz+2)^2}$.
			On en déduit que $|\varphi'(z)|^2 = \frac{9}{|iz+2|^4}$, soit $\frac{1}{(x^2 + (y-2)^2)^2} = \frac{1}{9} |\varphi'(z)|^2$.
			Par changement de variables $w = \varphi(z)$ :
			\[ I = \iint_D \frac{1}{9} |\varphi'(z)|^2 dxdy = \frac{1}{9} \iint_{\varphi(D)} dudv \]
			Comme $\varphi(D) = D$, l'intégrale devient :
			\[ I = \frac{1}{9} \text{Aire}(D) = \frac{\pi}{9} \]
		\end{enumerate}
		
	\end{proof}
	
	\setcounter{exercise}{12}
	\begin{exercise}
		\begin{enumerate}
			\item Soient $R > \epsilon > 0$ et $\gamma$ un lacet qui paramètre le bord de l'ouvert $\Omega = \{z \in \mathbb{C} \mid \epsilon < |z| < R \text{ et } \text{Im}(z) > 0\}$ dans le sens trigonométrique. Montrer que l'intégrale $\int_\gamma \frac{e^{iz}}{z} dz$ est nulle.
			\item En déduire la formule classique $\int_0^{+\infty} \frac{\sin t}{t} dt = \frac{\pi}{2}$.
		\end{enumerate}
	\end{exercise}
	
	\begin{proof}
		\begin{enumerate}
			\item On pose $f(z) = \frac{e^{iz}}{z}$. 
			La fonction $f$ est holomorphe sur $\mathbb{C}^* = \mathbb{C} \setminus \{0\}$.
			L'ouvert $\Omega$ est un demi-anneau situé dans le demi-plan supérieur. Son adhérence $\overline{\Omega}$ est un compact qui ne contient pas l'origine ($0 \notin \overline{\Omega}$ car $\epsilon > 0$).
			Ainsi, $f$ est holomorphe sur un ouvert simplement connexe contenant le compact $\overline{\Omega}$. 
			D'après le théorème de Cauchy, l'intégrale d'une fonction holomorphe sur un lacet fermé (ici le bord de $\Omega$ orienté positivement) est nulle :
			\[ \int_\gamma \frac{e^{iz}}{z} dz = 0 \]
			
			\item Le lacet $\gamma$ se décompose en quatre chemins :
			\begin{itemize}
				\item $\gamma_1$ : le segment réel $[\epsilon, R]$, paramétré par $z(t) = t$ avec $t \in [\epsilon, R]$.
				\item $\gamma_R$ : le grand demi-cercle, paramétré par $z(\theta) = Re^{i\theta}$ avec $\theta \in [0, \pi]$.
				\item $\gamma_2$ : le segment réel $[-R, -\epsilon]$, paramétré par $z(t) = t$ avec $t \in [-R, -\epsilon]$.
				\item $\gamma_\epsilon$ : le petit demi-cercle parcouru dans le sens anti-trigonométrique (pour fermer le lacet), paramétré par $z(\theta) = \epsilon e^{i\theta}$ avec $\theta$ allant de $\pi$ à $0$.
			\end{itemize}
			L'équation de la question 1 s'écrit :
			\[ \int_{\gamma_1} f(z) dz + \int_{\gamma_R} f(z) dz + \int_{\gamma_2} f(z) dz + \int_{\gamma_\epsilon} f(z) dz = 0 \]
			
			a) Regroupement des intégrales sur l'axe réel :
			\begin{align*}
				\int_{\gamma_1} f(z) dz + \int_{\gamma_2} f(z) dz &= \int_\epsilon^R \frac{e^{it}}{t} dt + \int_{-R}^{-\epsilon} \frac{e^{it}}{t} dt \\
				&= \int_\epsilon^R \frac{e^{it}}{t} dt + \int_R^\epsilon \frac{e^{-iu}}{-u} (-du) \quad \text{(changement de variable } u = -t \text{)} \\
				&= \int_\epsilon^R \frac{e^{it} - e^{-it}}{t} dt = 2i \int_\epsilon^R \frac{\sin(t)}{t} dt
			\end{align*}
			
			b) Majoration sur le grand cercle $\gamma_R$ (Lemme de Jordan) :
			\[ I_R = \int_{\gamma_R} \frac{e^{iz}}{z} dz = \int_0^\pi \frac{e^{iR(\cos\theta + i\sin\theta)}}{Re^{i\theta}} iR e^{i\theta} d\theta = i \int_0^\pi e^{-R\sin\theta} e^{iR\cos\theta} d\theta \]
			Majorons le module de cette intégrale :
			\[ |I_R| \leq \int_0^\pi e^{-R\sin\theta} d\theta = 2 \int_0^{\pi/2} e^{-R\sin\theta} d\theta \]
			Sur $[0, \pi/2]$, la concavité du sinus donne $\sin\theta \geq \frac{2}{\pi}\theta$, d'où :
			\[ |I_R| \leq 2 \int_0^{\pi/2} e^{-\frac{2R}{\pi}\theta} d\theta = 2 \left[ \frac{-\pi}{2R} e^{-\frac{2R}{\pi}\theta} \right]_0^{\pi/2} = \frac{\pi}{R} \left( 1 - e^{-R} \right) \]
			On a donc bien $\lim_{R \to +\infty} I_R = 0$.
			
			\textbf{c) Étude sur le petit cercle $\gamma_\epsilon$ :}
			Autour de $0$, on peut écrire $e^{iz} = 1 + iz + o(z)$. Donc $f(z) = \frac{1}{z} + i + o(1)$.
			L'intégrale devient :
			\[ I_\epsilon = \int_{\gamma_\epsilon} \frac{e^{iz}}{z} dz = \int_{\gamma_\epsilon} \frac{1}{z} dz + \int_{\gamma_\epsilon} g(z) dz \]
			où $g$ est une fonction bornée au voisinage de $0$. 
			La longueur du chemin $\gamma_\epsilon$ étant $\pi\epsilon$, l'intégrale de la fonction bornée tend vers $0$ quand $\epsilon \to 0$.
			Pour la partie singulière, on paramètre par $z(\theta) = \epsilon e^{i\theta}$ avec $\theta$ allant de $\pi$ à $0$ (sens horaire) :
			\[ \int_{\gamma_\epsilon} \frac{1}{z} dz = \int_\pi^0 \frac{1}{\epsilon e^{i\theta}} i\epsilon e^{i\theta} d\theta = i \int_\pi^0 d\theta = -i\pi \]
			Ainsi, $\lim_{\epsilon \to 0} I_\epsilon = -i\pi$.
			
			\textbf{d) Conclusion :}
			En passant à la limite quand $R \to +\infty$ et $\epsilon \to 0$ dans l'équation de Cauchy initiale, on obtient :
			\[ 2i \int_0^{+\infty} \frac{\sin(t)}{t} dt + 0 - i\pi = 0 \]
			En divisant par $2i$, on trouve finalement :
			\[ \int_0^{+\infty} \frac{\sin(t)}{t} dt = \frac{\pi}{2} \]
		\end{enumerate}
		
	\end{proof}
	
	\section{Topologie}
	
	\setcounter{exercise}{2}
	\begin{exercise}
		Soit $K, L$ deux espaces métriques compact et $\pi : K \rightarrow L$ une bijection continue.\\
		Montrer que $\pi$ est un homéomorphisme entre $K$ et $L$
	\end{exercise}
	\begin{proof}
		Pour prouver que $\pi$ est un homéomorphisme, il suffit de montrer que sa réciproque $\pi^{-1} : L \rightarrow K$ est continue.\\
		
		Soit $(y_n)_{n \in \mathbb{N}}$ une suite d'éléments de $L$ convergeant vers un élément $y \in L$. Posons :
		\[ x_n = \pi^{-1}(y_n) \quad \text{et} \quad x = \pi^{-1}(y) \]
		Montrons que la suite $(x_n)$ converge vers $x$ dans $K$.
		
		La suite $(x_n)$ est une suite d'éléments de l'espace métrique compact $K$. 
		Par Bolzano-Weierstrass, de toute suite d'un compact, on peut extraire une sous-suite convergente. Soit $(x_{\phi(n)})$ une telle sous-suite, et notons $z \in K$ sa limite :
		\[ x_{\phi(n)} \xrightarrow[n \to \infty]{} z \]
		
		L'application $\pi$ est continue sur $K$. Par caractérisation séquentielle de la continuité, l'image de la sous-suite doit converger vers l'image de sa limite :
		\[ \pi(x_{\phi(n)}) \xrightarrow[n \to \infty]{} \pi(z) \]
		Or, par construction, $\pi(x_{\phi(n)}) = y_{\phi(n)}$. 
		
		Comme la suite parente $(y_n)$ converge vers $y$, toute sous-suite extraite converge également vers $y$. On a donc, par unicité de la limite dans $L$ :
		\[ \pi(z) = y \]
		Puisque $\pi$ est une bijection, chaque élément possède un unique antécédent. Sachant que $\pi(x) = y$, l'injectivité de $\pi$ impose :
		\[ z = x \]
		
		Nous avons montré que toute sous-suite convergente de $(x_n)$ converge nécessairement vers $x$. Dans un espace compact, si une suite possède une unique valeur d'adhérence, alors elle converge vers cette valeur.
		
		Ainsi, $x_n \xrightarrow[n \to \infty]{} x$, ce qui prouve que $\pi^{-1}$ est continue en tout point $y \in L$. 
		
		Conclusion : $\pi$ est une bijection continue dont la réciproque est continue, c'est donc un homéomorphisme.
	\end{proof}
	

	\section{Intégration}
	
	\setcounter{exercise}{3}
	\begin{exercise}
		On travaille avec la mesure de Lebesgue sur $\mathbb{R}$ et on se donne une fonction continue par morceaux (par exemple) sur $\mathbb{R}$.
		
		\textbf{(1)} Montrer que si $f$ est positive, on a, lorsque $R \to +\infty$,
		\[
		\int_{-R}^{R} f \longrightarrow \int_{\mathbb{R}} f .
		\]
		
		\textbf{(2)} Montrer que si $f$ est intégrable, on a, lorsque $R \to +\infty$,
		\[
		\int_{-R}^{R} f \longrightarrow \int_{\mathbb{R}} f .
		\]
		
		\textbf{(3)} On suppose $f$ intégrable sur $\mathbb{R}$. Montrer que pour tout $\varepsilon > 0$, on peut trouver $g$ intégrable, bornée et à support compact telle que
		\[
		\int_{\mathbb{R}} |f-g| \le \varepsilon .
		\]
	\end{exercise}
		
		\begin{proof}
			\textbf{(1)}
			Supposons $f$ mesurable positive. Pour $R>0$, posons
			\[
			f_R = f \mathbf{1}_{[-R,R]}.
			\]
			Alors $(f_R)_{R>0}$ est une famille croissante de fonctions mesurables positives et
			\[
			f_R(x) \uparrow f(x) \quad \text{pour tout } x \in \mathbb{R}.
			\]
			Par le théorème de convergence monotone,
			\[
			\lim_{R \to +\infty} \int_{\mathbb{R}} f_R
			=
			\int_{\mathbb{R}} \lim_{R\to+\infty} f_R
			=
			\int_{\mathbb{R}} f.
			\]
			Or
			\[
			\int_{\mathbb{R}} f_R
			=
			\int_{-R}^{R} f.
			\]
			On en déduit
			\[
			\int_{-R}^{R} f \longrightarrow \int_{\mathbb{R}} f.
			\]
			
			\textbf{(2)} Supposons maintenant $f \in L^1(\mathbb{R})$. Alors $|f|$ est intégrable. On applique le résultat précédent à la fonction positive $|f|$ :
			\[
			\int_{-R}^{R} |f| \longrightarrow \int_{\mathbb{R}} |f|.
			\]
			On écrit
			\[
			\int_{\mathbb{R}} f - \int_{-R}^{R} f
			=
			\int_{|x|>R} f(x)\,dx.
			\]
			Donc
			\[
			\left| \int_{\mathbb{R}} f - \int_{-R}^{R} f \right|
			\le
			\int_{|x|>R} |f|.
			\]
			Or
			\[
			\int_{|x|>R} |f|
			=
			\int_{\mathbb{R}} |f| - \int_{-R}^{R} |f|
			\longrightarrow 0.
			\]
			Ainsi
			\[
			\int_{-R}^{R} f \longrightarrow \int_{\mathbb{R}} f.
			\]
			
			\textbf{(3)} Soit $f \in L^1(\mathbb{R})$ et $\varepsilon > 0$.
			
			
			\textbf{Étape 1 : troncature du support.}
			
			D'après le point (2), il existe $R>0$ tel que
			\[
			\int_{|x|>R} |f(x)|\,dx < \frac{\varepsilon}{2}.
			\]
			Posons
			\[
			f_1 = f \mathbf{1}_{[-R,R]}.
			\]
			Alors
			\[
			\int_{\mathbb{R}} |f-f_1|
			=
			\int_{|x|>R} |f|
			<
			\frac{\varepsilon}{2}.
			\]
			
			
			\textbf{Étape 2 : troncature des valeurs.}
			
			Pour $M>0$, posons
			\[
			f_{1,M}(x) =
			\begin{cases}
				f_1(x) & \text{si } |f_1(x)| \le M, \\
				M\,\mathrm{sgn}(f_1(x)) & \text{sinon}.
			\end{cases}
			\]
			Alors $f_{1,M}$ est bornée par $M$ et a toujours son support dans $[-R,R]$.
			
			Comme $f_1 \in L^1$, on a
			\[
			\int_{\{|f_1|>M\}} |f_1| \longrightarrow 0
			\quad \text{lorsque } M \to +\infty.
			\]
			Donc il existe $M>0$ tel que
			\[
			\int_{\{|f_1|>M\}} |f_1|
			<
			\frac{\varepsilon}{2}.
			\]
			Or
			\[
			|f_1 - f_{1,M}|
			\le
			|f_1| \mathbf{1}_{\{|f_1|>M\}},
			\]
			donc
			\[
			\int_{\mathbb{R}} |f_1 - f_{1,M}|
			<
			\frac{\varepsilon}{2}.
			\]
			
			\medskip
			
			\textbf{Conclusion.}
			
			Posons $g = f_{1,M}$. Alors $g$ est intégrable, bornée, à support compact et
			\[
			\int_{\mathbb{R}} |f-g|
			\le
			\int_{\mathbb{R}} |f-f_1|
			+
			\int_{\mathbb{R}} |f_1-g|
			<
			\frac{\varepsilon}{2}
			+
			\frac{\varepsilon}{2}
			=
			\varepsilon.
			\]
			
			\bigskip
			
			Ceci achève la démonstration.
		\end{proof}
	
	\section{Espaces de Hilbert}
	
	\setcounter{exercise}{9}
	\begin{exercise}{(Opérateurs de Hilbert-Schmidt)}
		Soit $H$ un espace de Hilbert muni d'une base hilbertienne $(e_i)_{i \in \mathbb{N}}$. Pour $u \in B(H)$, on pose : 
		\[ \|u\|_{HS} = \sqrt{\sum_{i=0}^{+\infty} \|u(e_i)\|^2}, \text{ puis } \mathcal{HS}(H) = \{u \in B(H) \mid \|u\|_{HS} < +\infty \}. \]
		
		\begin{enumerate}
			\item Soient $u \in B(H)$ et $(f_j)$ une (autre) base hilbertienne de $H$. Vérifier la formule :
			\[ \sum_{i,j} |\langle u(e_i), f_j \rangle|^2 = \|u\|_{HS}^2 ; \]
			en déduire que $\|u^*\|_{HS} = \|u\|_{HS}$ et que $\|u\|_{HS}$ ne dépend pas de la base hilbertienne $(e_i)$ choisie.
			\item Montrer que $\mathcal{HS}(H)$ est un idéal bilatère de l'algèbre $B(H)$.
			\item Montrer que tout $u \in \mathcal{HS}(H)$ vérifie $\|u\| \le \|u\|_{HS}$.
			\item Montrer que $(\mathcal{HS}(H), \|\cdot\|_{HS})$ est un espace de Banach.
		\end{enumerate}
	\end{exercise}
	
	\begin{proof}
		\begin{enumerate}
			\item Fixons $i \in \mathbb{N}$. Comme $(f_j)$ est une base hilbertienne, l'égalité de Parseval donne :
			\[ \|u(e_i)\|^2 = \sum_{j=0}^{+\infty} |\langle u(e_i), f_j \rangle|^2. \]
			En sommant sur $i$, on obtient :
			\[ \sum_{i,j} |\langle u(e_i), f_j \rangle|^2 = \sum_i \|u(e_i)\|^2 = \|u\|_{HS}^2. \]
			Par ailleurs, on sait que $\langle u(e_i), f_j \rangle = \langle e_i, u^*(f_j) \rangle = \overline{\langle u^*(f_j), e_i \rangle}$. Donc :
			\[ \sum_{i,j} |\langle u(e_i), f_j \rangle|^2 = \sum_j \left( \sum_i |\langle u^*(f_j), e_i \rangle|^2 \right). \]
			En utilisant Parseval pour la base $(e_i)$ cette fois, la somme intérieure vaut $\|u^*(f_j)\|^2$. On en déduit $\|u\|_{HS}^2 = \sum_j \|u^*(f_j)\|^2 = \|u^*\|_{HS}^2$ (calculé dans la base $f$). Cela prouve que la valeur ne dépend pas de la base de départ et que $\|u\|_{HS} = \|u^*\|_{HS}$.
			
			\item Soit $u \in \mathcal{HS}(H)$ et $v \in B(H)$.
			\begin{itemize}
				\item à gauche : $\|vu\|_{HS}^2 = \sum_i \|v(u(e_i))\|^2 \le \sum_i \|v\|^2 \|u(e_i)\|^2 = \|v\|^2 \|u\|_{HS}^2 < \infty$.
				\item à droite : en utilisant la question précédente : $\|uv\|_{HS} = \|(uv)^*\|_{HS} = \|v^* u^*\|_{HS}$. Comme $v^* \in B(H)$ et $u^* \in \mathcal{HS}(H)$, on se ramène au cas précédent : $\|uv\|_{HS} \le \|v^*\| \|u^*\|_{HS} = \|v\| \|u\|_{HS} < \infty$.
			\end{itemize}
			
			\item Soit $x \in H$ tel que $\|x\|=1$. On peut compléter $x$ en une base hilbertienne $(g_i)$ telle que $g_0 = x$. Alors :
			\[ \|u(x)\|^2 = \|u(g_0)\|^2 \le \sum_{i=0}^{+\infty} \|u(g_i)\|^2 = \|u\|_{HS}^2. \]
			En prenant le supremum sur les $x$ de norme 1, on obtient $\|u\| \le \|u\|_{HS}$.
			
			\item $\mathcal{HS}(H)$ est un espace préhilbertien pour le produit scalaire $\langle u, v \rangle_{HS} = \sum_i \langle u(e_i), v(e_i) \rangle$. Montrons qu'il est complet. 
			Soit $(u_n)$ une suite de Cauchy pour $\|\cdot\|_{HS}$. D'après la Q3, elle est aussi de Cauchy pour $\|\cdot\|$, donc $u_n \to u$ dans $B(H)$.
			Pour tout $N \in \mathbb{N}$, $\sum_{i=0}^N \|(u_n - u_m)(e_i)\|^2 \le \|u_n - u_m\|_{HS}^2$.
			En fixant $n$ et en faisant tendre $m \to \infty$ : $\sum_{i=0}^N \|(u_n - u)(e_i)\|^2 \le \epsilon^2$.
			En faisant enfin tendre $N \to \infty$, on a $\|u_n - u\|_{HS} \le \epsilon$. Ainsi $u_n - u \in \mathcal{HS}(H)$, donc $u \in \mathcal{HS}(H)$ et $u_n \to u$ pour la norme HS.
		\end{enumerate}
	\end{proof}
	
	\section{Séries de Fourier}
	
	\setcounter{exercise}{5}
	\begin{exercise}{(Critère d'équirépartition)}
		On se donne une suite $(x_n)$ de réels telle que
		\[ \forall k \in \mathbb{Z} \setminus \{0\}, \qquad \lim_{N \to +\infty} \frac{1}{N} \sum_{n=1}^N e^{ikx_n} = 0. \]
		Montrer que pour toute fonction $f$ continue $2\pi$-périodique on a
		\[ \lim_{N \to +\infty} \frac{1}{N} \sum_{n=1}^N f(x_n) = \frac{1}{2\pi} \int_0^{2\pi} f(t) dt. \]
	\end{exercise}
	
	\begin{proof}
		Étape 1 : Cas des polynômes trigonométriques \\
		Soit $P$ un polynôme trigonométrique. Par définition, il existe un entier $M \geq 0$ et des coefficients complexes $(c_k)_{-M \leq k \leq M}$ tels que pour tout $x \in \mathbb{R}$,
		\[ P(x) = \sum_{k=-M}^M c_k e^{ikx}. \]
		Calculons la moyenne de $P$ sur les $N$ premiers termes de la suite $(x_n)$ :
		\[ \frac{1}{N} \sum_{n=1}^N P(x_n) = \frac{1}{N} \sum_{n=1}^N \sum_{k=-M}^M c_k e^{ikx_n} = \sum_{k=-M}^M c_k \left( \frac{1}{N} \sum_{n=1}^N e^{ikx_n} \right). \]
		Par hypothèse, pour tout $k \neq 0$, on a $\lim_{N \to +\infty} \frac{1}{N} \sum_{n=1}^N e^{ikx_n} = 0$. 
		Pour $k = 0$, la moyenne vaut exactement $1$ quel que soit $N$. Par linéarité de la limite (la somme étant finie), on obtient :
		\[ \lim_{N \to +\infty} \frac{1}{N} \sum_{n=1}^N P(x_n) = c_0. \]
		Par ailleurs, calculons l'intégrale de $P$ sur une période :
		\[ \frac{1}{2\pi} \int_0^{2\pi} P(t) dt = \sum_{k=-M}^M c_k \left( \frac{1}{2\pi} \int_0^{2\pi} e^{ikt} dt \right) = c_0, \]
		car l'intégrale de $e^{ikt}$ sur $[0, 2\pi]$ est nulle pour $k \neq 0$, et vaut $2\pi$ pour $k = 0$.
		Le résultat est donc vérifié pour tout polynôme trigonométrique.\\
		
		Étape 2 : Généralisation aux fonctions continues par densité\\
		Soit $f$ une fonction continue et $2\pi$-périodique sur $\mathbb{R}$, et soit $\varepsilon > 0$.
		D'après le théorème d'approximation de Weierstrass trigonométrique (ou théorème de Stone-Weierstrass), il existe un polynôme trigonométrique $P$ tel que $\|f - P\|_\infty \leq \varepsilon$, où $\| \cdot \|_\infty$ désigne la norme de la convergence uniforme sur $\mathbb{R}$.
		
		Majorons la différence qui nous intéresse en insérant judicieusement le polynôme $P$ et en utilisant l'inégalité triangulaire :
		\begin{align*}
			\Delta_N &= \left| \frac{1}{N} \sum_{n=1}^N f(x_n) - \frac{1}{2\pi} \int_0^{2\pi} f(t) dt \right| \\
			&\leq \underbrace{\left| \frac{1}{N} \sum_{n=1}^N (f(x_n) - P(x_n)) \right|}_{A_N} 
			+ \underbrace{\left| \frac{1}{N} \sum_{n=1}^N P(x_n) - \frac{1}{2\pi} \int_0^{2\pi} P(t) dt \right|}_{B_N} 
			+ \underbrace{\left| \frac{1}{2\pi} \int_0^{2\pi} (P(t) - f(t)) dt \right|}_{C}
		\end{align*}
		
		Majorons chaque terme :
		\begin{enumerate}
			\item Le terme $A_N$ : $\displaystyle A_N \leq \frac{1}{N} \sum_{n=1}^N |f(x_n) - P(x_n)| \leq \frac{1}{N} \sum_{n=1}^N \|f - P\|_\infty \leq \varepsilon$.
			\item Le terme $C$ : $\displaystyle C \leq \frac{1}{2\pi} \int_0^{2\pi} |P(t) - f(t)| dt \leq \frac{1}{2\pi} \int_0^{2\pi} \|P - f\|_\infty dt \leq \varepsilon$.
			\item Le terme $B_N$ : Puisque le résultat a été démontré à l'étape 1 pour le polynôme $P$, on sait que $B_N \xrightarrow[N \to +\infty]{} 0$. Il existe donc un entier $N_0$ tel que pour tout $N \geq N_0$, on ait $B_N \leq \varepsilon$.
		\end{enumerate}
		
		En regroupant ces majorations, on obtient que pour tout $N \geq N_0$ :
		\[ \Delta_N \leq \varepsilon + \varepsilon + \varepsilon = 3\varepsilon. \]
	\end{proof}
	
	\section{Transformée de Fourier}
	
	\setcounter{exercise}{1}
	\begin{exercise}{(Variante)}
		Soit $f$ une fonction intégrable nulle en dehors du segment $[-a, a]$, $a > 0$. Montrer que $\hat{f}$ s'étend en une fonction holomorphe sur $\mathbb{C}$, qui de plus vérifie 
		\[ |\hat{f}(iy)| \le C e^{2a|y|}, \quad \forall y \in \mathbb{R}. \]
	\end{exercise}
	
	\begin{proof}

	\begin{enumerate}
		\item Extension holomorphe sur $\mathbb{C}$ :
		La transformée de Fourier de $f$ pour $\xi \in \mathbb{R}$ est définie par :
		\[ \hat{f}(\xi) = \int_{-\infty}^{+\infty} f(t) e^{-it\xi} \, dt = \int_{-a}^{a} f(t) e^{-it\xi} \, dt \]
		Pour étendre cette fonction au plan complexe, on définit pour $z \in \mathbb{C}$ :
		\[ F(z) = \int_{-a}^{a} f(t) e^{-itz} \, dt \]
		Vérifions les conditions du théorème de dérivation sous le signe intégral (version holomorphe) :
		\begin{itemize}
			\item Pour presque tout $t \in [-a, a]$, la fonction $z \mapsto f(t) e^{-itz}$ est entière (holomorphe sur $\mathbb{C}$).
			\item La fonction $t \mapsto f(t) e^{-itz}$ est mesurable (et intégrable car $f \in L^1$ et l'exponentielle est bornée sur le segment $[-a, a]$ pour $z$ fixé).
			\item Domination locale : Soit $K$ un compact de $\mathbb{C}$. Il existe $M > 0$ tel que pour tout $z \in K$, $|\text{Im}(z)| \le M$. Pour $t \in [-a, a]$ et $z \in K$ :
			\[ |f(t) e^{-itz}| = |f(t)| \cdot |e^{-it(\text{Re}(z) + i\text{Im}(z))}| = |f(t)| e^{t\text{Im}(z)} \le |f(t)| e^{aM} \]
			La fonction $t \mapsto |f(t)| e^{aM}$ est intégrable sur $[-a, a]$.
		\end{itemize}
		Ainsi, $F$ est holomorphe sur $\mathbb{C}$ et coïncide avec $\hat{f}$ sur l'axe réel.
		
		\item Soit $y \in \mathbb{R}$. On calcule $\hat{f}(iy)$ en utilisant l'extension précédente :
		\[ |\hat{f}(iy)| = \left| \int_{-a}^{a} f(t) e^{-it(iy)} \, dt \right| = \left| \int_{-a}^{a} f(t) e^{ty} \, dt \right| \]
		En utilisant l'inégalité triangulaire intégrale :
		\[ |\hat{f}(iy)| \le \int_{-a}^{a} |f(t)| e^{ty} \, dt \]
		Comme $t \in [-a, a]$, on a $ty \le |t| \cdot |y| \le a|y|$. L'exponentielle étant croissante :
		\[ e^{ty} \le e^{a|y|} \]
		D'où :
		\[ |\hat{f}(iy)| \le \left( \int_{-a}^{a} |f(t)| \, dt \right) e^{a|y|} \]
		En posant $C = \|f\|_1 = \int_{-a}^{a} |f(t)| \, dt$, on obtient $|\hat{f}(iy)| \le C e^{a|y|}$.
		
		Enfin, puisque $a > 0$ et $|y| \ge 0$, on a $a|y| \le 2a|y|$, ce qui implique $e^{a|y|} \le e^{2a|y|}$. On a donc bien la majoration demandée :
		\[ |\hat{f}(iy)| \le C e^{2a|y|} \]
	\end{enumerate}

	\end{proof}
	
	\setcounter{exercise}{4}
	\begin{exercise}{(Polynômes et fonctions de Hermite)}
		On travaille dans l'espace de Hilbert $H = L^2(\mathbb{R}, \mu)$ associé à la mesure (gaussienne standard) de probabilité $\mu$ sur $\mathbb{R}$ définie par $d\mu(x) = \frac{e^{-x^2/2}}{\sqrt{2\pi}}dx$. Pour $n \in \mathbb{N}$ et $x \in \mathbb{R}$, on note :
		\[ h_n(x) = e^{x^2/2}g^{(n)}(x), \quad \text{où} \quad g(x) = e^{-x^2/2}. \]
		
		\begin{enumerate}
			\item Montrer que les fonctions $h_n$ sont polynomiales. Déterminer leurs degrés et coefficients dominants.
			\item Montrer que $(h_n)_{n\in\mathbb{N}}$ forme une famille orthogonale de $H$ et calculer la norme $\lambda_n$ de chaque élément $h_n$.
			\item On veut montrer que la famille $(\lambda_n^{-1}h_n)_{n\in\mathbb{N}}$ est une base hilbertienne de $H$.
			\begin{enumerate}
				\item Expliquer pourquoi il suffit de montrer que les polynômes sont denses dans $H$.
				\item Pour $f \in H$ et $x \in \mathbb{R}$, on note $\psi_f(x) = f(x)e^{-x^2/2}$. Montrer que sa transformée de Fourier $\widehat{\psi_f}$ est bien définie sur $\mathbb{R}$ et qu'elle s'étend en une fonction holomorphe sur $\mathbb{C}$.
				\item Pour tout $n \in \mathbb{N}$, calculer la dérivée $n$-ième $\widehat{\psi_f}^{(n)}(0)$. En déduire que si $f$ est orthogonale à tous les polynômes, alors $f$ est nulle.
				\item Conclure.
			\end{enumerate}
		\end{enumerate}
	\end{exercise}
	
	\begin{proof}
		1. Par récurrence, montrons que $g^{(n)}(x) = P_n(x)e^{-x^2/2}$ où $P_n$ est un polynôme de degré $n$ et de coefficient dominant $(-1)^n$.
		\begin{itemize}
			\item Pour $n=0$, $g^{(0)}(x) = e^{-x^2/2}$, donc $P_0(x)=1$. La propriété est vraie.
			\item Supposons $g^{(n)}(x) = P_n(x)e^{-x^2/2}$. Alors :
			\[ g^{(n+1)}(x) = \frac{d}{dx}(P_n(x)e^{-x^2/2}) = (P_n'(x) - x P_n(x))e^{-x^2/2} \]
			Ainsi $P_{n+1}(x) = P_n'(x) - x P_n(x)$. Si $P_n$ est de degré $n$ et de coefficient dominant $a_n$, alors $-xP_n$ est de degré $n+1$ et de coefficient dominant $-a_n$. Le terme $P_n'$ est de degré $n-1$, il ne modifie pas le degré dominant.
		\end{itemize}
		Par construction, $h_n(x) = e^{x^2/2} (P_n(x)e^{-x^2/2}) = P_n(x)$. 
		\textbf{Conclusion :} $h_n$ est un polynôme de \textbf{degré $n$} et de \textbf{coefficient dominant $(-1)^n$}.\\
		
		2. Soient $m, n \in \mathbb{N}$ avec $m < n$. Le produit scalaire dans $H$ est :
		\[ \langle h_n, h_m \rangle_\mu = \int_{\mathbb{R}} h_n(x) h_m(x) \frac{e^{-x^2/2}}{\sqrt{2\pi}} dx = \frac{1}{\sqrt{2\pi}} \int_{\mathbb{R}} \left( e^{x^2/2} g^{(n)}(x) \right) h_m(x) e^{-x^2/2} dx = \frac{1}{\sqrt{2\pi}} \int_{\mathbb{R}} g^{(n)}(x) h_m(x) dx \]
		Par intégrations par parties successives ($n$ fois), les termes de bord s'annulent car les dérivées de la gaussienne tendent vers $0$ :
		\[ \langle h_n, h_m \rangle_\mu = \frac{(-1)^n}{\sqrt{2\pi}} \int_{\mathbb{R}} g(x) h_m^{(n)}(x) dx \]
		Comme $\deg(h_m) = m < n$, on a $h_m^{(n)}(x) = 0$, donc $\langle h_n, h_m \rangle_\mu = 0$. La famille est orthogonale.
		
		Pour la norme $\lambda_n^2 = \langle h_n, h_n \rangle_\mu$ :
		\[ \lambda_n^2 = \frac{(-1)^n}{\sqrt{2\pi}} \int_{\mathbb{R}} g(x) h_n^{(n)}(x) dx \]
		Or $h_n(x) = (-1)^n x^n + \dots$, donc $h_n^{(n)}(x) = (-1)^n n!$. D'où :
		\[ \lambda_n^2 = \frac{(-1)^n (-1)^n n!}{\sqrt{2\pi}} \int_{\mathbb{R}} e^{-x^2/2} dx = \frac{n!}{\sqrt{2\pi}} \times \sqrt{2\pi} = n! \]
		\textbf{Conclusion :} $\lambda_n = \sqrt{n!}$.\\
		
		3.a) Puisque $\deg(h_n) = n$, toute combinaison linéaire des $h_k$ ($k \le n$) décrit l'espace des polynômes de degré au plus $n$. Si les polynômes sont denses dans $H$, alors l'adhérence de $\text{Vect}(h_n)_{n\in\mathbb{N}}$ est $H$. Comme la famille est orthonormale (après division par $\lambda_n$), c'est une base hilbertienne.\\
		
		3.b) $f \in H$ signifie $\int |f|^2 d\mu < \infty$. $\psi_f(x) = f(x)e^{-x^2/2}$.\\
		Par Cauchy-Schwarz, sa transformée de Fourier $\widehat{\psi_f}(\xi) = \int f(x) e^{-x^2/2} e^{-ix\xi} dx$ est bien définie car $\psi_f \in L^1(\mathbb{R})$ :
		\[ \int |f(x)| e^{-x^2/2} dx = \sqrt{2\pi} \int |f(x)| e^{-x^2/4} \frac{e^{-x^2/4}}{\sqrt{2\pi}} dx \le \sqrt{2\pi} \|f\|_H \|e^{-x^2/4}\|_H < \infty \]
		L'extension holomorphe $F(z) = \int f(x) e^{-x^2/2} e^{-ixz} dx$ pour $z \in \mathbb{C}$ est justifiée par le fait que pour $z = u+iv$, $|e^{-ixz}| = e^{xv}$. Le terme $e^{-x^2/2}$ assure la convergence et la domination pour tout $z \in \mathbb{C}$ (croissance exponentielle vs décroissance gaussienne).\\
		
		3.c) On a 
		\[\widehat{\psi_f}^{(n)}(0) = \int f(x) e^{-x^2/2} (-ix)^n dx = (-i)^n \sqrt{2\pi} \int f(x) x^n \frac{e^{-x^2/2}}{\sqrt{2\pi}} dx = (-i)^n \sqrt{2\pi} \langle f, x^n \rangle_\mu\]
		Si $f$ est orthogonale à tous les polynômes, alors $\langle f, x^n \rangle_\mu = 0$ pour tout $n$, donc $\widehat{\psi_f}^{(n)}(0) = 0$.
		Comme $\widehat{\psi_f}$ est une fonction analytique (holomorphe sur $\mathbb{C}$), ses coefficients de Taylor en 0 sont tous nuls, donc $\widehat{\psi_f} \equiv 0$. Par injectivité de la transformée de Fourier, $\psi_f = 0$ p.p., donc $f = 0$ p.p.\\
		
		3.d) L'orthogonal de l'espace des polynômes est $\{0\}$, donc les polynômes sont denses dans $H$. La famille $(\lambda_n^{-1} h_n)$ est donc une base hilbertienne.
	\end{proof}
	
	\begin{exercise}{(Échantillonnage de Shannon)}
		On montre que les signaux à bande limitée peuvent se reconstruire à partir de la donnée d'une suite de valeurs. Formellement, on s'intéresse aux fonctions dont la transformée de Fourier est à support compact.
		
		\begin{enumerate}
			\item Soit \( f \in L^1(\mathbb{R}) \) tel que (sans perte de généralité) \( \hat{f}(x) = 0 \) pour tout \( |x| > \pi \).
			\begin{enumerate}
				\item Rappeler pourquoi \( f \) admet un représentant continu, qui est en fait \( C^\infty \), sur \( \mathbb{R} \) et que pour tout \( t \in \mathbb{R} \),
				\[
				f(t) = \frac{1}{\sqrt{2\pi}} \int_{-\pi}^{\pi} \hat{f}(x) e^{ixt} dx.
				\]
				\item \textbf{Heuristique} = à ne pas mettre sur une copie. Sans chercher à justifier les calculs, montrer que :
				\[
				\hat{f}(x) = \sqrt{2\pi} \sum_{k \in \mathbb{Z}} f(k) e^{-2i\pi kx},
				\]
				(On pourra considérer la fonction \( 2\pi \)-périodique \( g \) qui vaut \( g(x) = \hat{f}(x) \) sur \( [-\pi, \pi] \) puis que
				\[
				f(t) = \sqrt{2\pi} \sum_{k \in \mathbb{Z}} f(k) \frac{\sin(\pi(t-k))}{\pi(t-k)}.
				\]
			\end{enumerate}
			
			\item Soit \( u \) une fonction de \( L^2(\mathbb{R}) \) dont la transformée de Fourier \( L^2 \), encore notée \( \hat{u} \), est nulle (presque partout) en dehors d'un segment de \( \mathbb{R} \). Montrer que \( \hat{u} \) est intégrable et que pour presque tout \( x \in \mathbb{R} \),
			\[
			\hat{\hat{u}}(x) = u(-x),
			\]
			et en déduire qu'il existe \( v \in \mathcal{C}_0(\mathbb{R}) \) telle que \( u = v \) presque partout.
			
			\item On introduit l'espace
			\[
			B = \left\{ u \in L^2(\mathbb{R}) ; \, \hat{u} = 0 \text{ pp sur } \mathbb{R} \setminus [-\pi, \pi] \right\}.
			\]
			Montrer que \( B \) est un sous-espace fermé de \( L^2(\mathbb{R}) \), sur lequel \( \| \cdot \|_\infty \leq \| \cdot \|_2 \).
			
			\item On posera \( \text{sinc}(t) = \frac{\sin(t)}{t} \) et pour \( n \in \mathbb{Z} \),
			\[
			s_n(x) = \sqrt{2\pi} \text{sinc}(\pi(x-n)).
			\]
			Montrer que la famille \( (s_n)_{n \in \mathbb{Z}} \) forme une base hilbertienne de \( B \).
			
			\item Montrer que pour tout \( u \in B \) on a
			\[
			u = \sum_{n \in \mathbb{Z}} f(n) s_n
			\]
			dans \( L^2(\mathbb{R}) \), c'est-à-dire avec convergence dans \( L^2 \) de la série, et que si on note encore \( u \) le représentant continu, on a pour tout \( x \in \mathbb{R} \)
			\[
			u(x) = \sum_{n \in \mathbb{Z}} f(n) s_n(x)
			\]
			avec convergence uniforme de la série sur \( \mathbb{R} \).
		\end{enumerate}
	\end{exercise}
	
	\begin{proof}
		\begin{enumerate}
			\item \begin{enumerate}
				\item Comme $\hat{f}$ est à support compact, pour tout $n\in\mathbb{N}$, $|\hat{f}|=o(\frac{1}{|x^n|})$ en $|x|\rightarrow \infty$, donc $f\in\mathcal{C}^\infty$.\\
				En particulier, $\hat{f}\in L¹$ donc la formule d'inversion de Fourier donne 
				\[\forall t \in\mathbb{R}, f(t)=\frac{1}{2\pi}\int_{[-\pi,\pi]}\hat{f}(x)e^{ixt}dx\]
				\item \textbf{Heuristique :}
				Sur $[-\pi, \pi]$, $\hat{f}$ peut être développée en série de Fourier. Les coefficients sont :
				$c_k = \frac{1}{2\pi} \int_{-\pi}^\pi \hat{f}(x)e^{-ikx} dx$. D'après la formule d'inversion en $t=k$, on voit que $c_k = \frac{1}{\sqrt{2\pi}} f(-k)$.
				Le développement est $\hat{f}(x) = \sum \frac{1}{\sqrt{2\pi}} f(-k) e^{ikx}$. En changeant $k$ en $-k$, on obtient la formule de l'énoncé. 
				En injectant cette somme dans l'intégrale d'inversion :
				\[ f(t) = \frac{1}{\sqrt{2\pi}} \int_{-\pi}^\pi \left( \sqrt{2\pi} \sum_{k \in \mathbb{Z}} f(k) e^{-ikx} \right) e^{ixt} dx = \sum_{k \in \mathbb{Z}} f(k) \int_{-\pi}^\pi e^{ix(t-k)} dx \]
				L'intégrale vaut $\left[ \frac{e^{ix(t-k)}}{i(t-k)} \right]_{-\pi}^\pi = \frac{2 \sin(\pi(t-k))}{t-k}$. D'où le résultat.
			\end{enumerate}
				
			\item Si $\hat{u} \in L^2(\mathbb{R})$ est à support compact $K$, alors par l'inégalité de Cauchy-Schwarz :
			\[ \int_K |\hat{u}(x)| dx \leq \sqrt{\text{mes}(K)} \left( \int_K |\hat{u}(x)|^2 dx \right)^{1/2} < \infty \]
			Donc $\hat{u} \in L^1(\mathbb{R})$. Puisque $\hat{u} \in L^1 \cap L^2$, la formule d'inversion $L^1$ s'applique presque partout. On applique le résultat de la question 1 pour $f=u$, et on définit $v$ comme la transformée de Fourier inverse de $\hat{u}$.
				
			\item Posons $\Psi:L^{2}\rightarrow L^{2}$ l'application définie par $\Psi:u\rightarrow\widehat{u}\mathbf{1}_{[-\pi,\pi]}$ qui est une application linéaire continue par propriétés de la transformée de Fourier. On a donc $B=\ker\Psi$ qui est donc fermé.\\
			$B$ est l'image réciproque du sous-espace fermé $\{ \phi \in L^2 \mid \phi = 0 \text{ sur } \mathbb{R} \setminus [-\pi, \pi] \}$ par la transformée de Fourier. Comme cette dernière est une isométrie de $L^2$ (théorème de Plancherel), $B$ est fermé. \\
			Pour l'inégalité, si $u \in B$, $u(x) = \frac{1}{\sqrt{2\pi}} \int_{-\pi}^\pi \hat{u}(\xi)e^{ix\xi} d\xi$.
			Par Cauchy-Schwarz : $|u(x)| \leq \frac{1}{\sqrt{2\pi}} \sqrt{2\pi} \|\hat{u}\|_2 = \|u\|_2$. Donc $\|u\|_\infty \leq \|u\|_2$.
				
			\item Posons pour tout $n\in\mathbb{Z}$,
			\[f_n(t)=e^{int}\mathbf{1}_{[-\pi,\pi]}(t),\text{ pour tout }t\in\mathbb{R}\]
			Alors pour $x\in\mathbb{R}$,
			\[\widehat{f_n(x)}=\int_\mathbb{R}e^{i(n-x)t}\mathbf{1}_{[-\pi,\pi]}(t)dt=2\pi s_n(x)\]
			On en déduit ainsi $\widehat{s_n(x)}=e^{-inx}\mathbf{1}_{[-\pi,\pi]}(x)$ pp.\\
			Par Plancherel, pour $n,m\in\mathbb{Z}$ distincts :
			\[\langle s_n,s_m\rangle=\frac{1}{2\pi}\langle \widehat{s_n}\widehat{s_m}\rangle=\frac{1}{2\pi}\int_{[-\pi,\pi]}e^{-i(n-m)x}dx=\delta_{n,m}\]
			Donc $(s_n)_{n\in\mathbb{Z}}$ est une famille orthonormée.\\
			Soit $u\in B$ telle que $\forall n\in\mathbb{Z}, \langle u,s_n\rangle=0$. Alors par Plancherel $\forall n\in\mathbb{Z}, \langle \widehat{u},\widehat{s_n}\rangle=0$, c'est à dire
			\[\forall n\in\mathbb{Z}, \int_{[-\pi,\pi]}\widehat{u}(x)e^{-inx}dx=0\]
			En considérant $\tilde{\widehat{u}}$ étendue par $2\pi$ périodicité, on a $\forall n\in\mathbb{Z}, \tilde{u}(n)=0$, donc $\tilde{u}=0$ pp et donc $u=0$ pp sur $[\pi,\pi]$. Ainsi la famille $(s_n)_{n\in\mathbb{Z}}$ est dense dans $L^{2}$. C'est donc une base hilbertienne de $B$.
				
			\item Comme $(s_n)$ est une base hilbertienne de $B$, tout $u \in B$ s'écrit $u = \sum \langle u, s_n \rangle s_n$ avec convergence dans $L^2$. 
			Le coefficient est $\langle u, s_n \rangle = \int u(x) s_n(x) dx$. Par Plancherel, c'est aussi :
			\[\langle \hat{u}, \hat{s}_n \rangle = \frac{1}{2\pi}\int_{-\pi}^{\pi}\widehat{u}(x)e^{inx}dx= u(n)\]
			En utilisant le résultat de la première question.\\
			Enfin, la convergence uniforme découle de l'inégalité sur les normes obtenue à la question 3 :
			\[ \|u - \sum_{n=-N}^N u(n) s_n \|_\infty \leq \|u - \sum_{n=-N}^N u(n) s_n \|_2 \xrightarrow[N \to \infty]{} 0 \]
			\item (Lien avec le théorème de Shannon en physique) En physique, le théorème de Shannon dit que pour ne pas perdre d'information lors de l'échantillonage d'un signal, il faut échantillonner à une fréquence supérieure à deux fois la fréquence maximale du signal. Dans l'exercice, la fréquence maximale du signal est $\pi$ puisque sa transformée de Fourier (ses fréquences) sont nulles au-delà. On doit donc échantillonner à une fréquence d'au moins $2\pi$, donc une période $T=\frac{2\pi}{2\pi}=1$ pour ne pas perdre d'information (c'est bien le cas ici). Lorsque la condition n'est pas respectée, on perd de l'information et on parle de repliement de spectre.
			\centering
			\includegraphics[width=0.8\textwidth]{img/shannon.png}			

		\end{enumerate}
	\end{proof}
	
	
	\section{Calcul différentiel}
	
	\setcounter{exercise}{2}
	\begin{exercise}
		Soit $F : \mathbb{R}^n \to \mathbb{R}^n$ une fonction de classe $C^1$ pour laquelle il existe $\delta > 0$ tel que 
		\[ \|F(x) - F(y)\| \ge \delta \|x - y\| \quad \text{pour tout } x, y \in \mathbb{R}^n. \]
		\begin{enumerate}
			\item Montrer que $F$ est injective et que $F(\mathbb{R}^n)$ est fermé.
			\item Montrer que $dF$ est inversible en tout point de $\mathbb{R}^n$.
			\item Montrer que $F(\mathbb{R}^n)$ est ouvert, et en déduire que $F$ est un $C^1$ difféomorphisme de $\mathbb{R}^n$ dans $\mathbb{R}^n$.
		\end{enumerate}
	\end{exercise}
	
	\begin{proof}
	\begin{enumerate}
		\item Injectivité et caractère fermé :
		\begin{itemize}
			\item Injectivité : Soient $x, y \in \mathbb{R}^n$ tels que $F(x) = F(y)$. L'inégalité donne $0 = \|F(x) - F(y)\| \ge \delta \|x - y\|$. Comme $\delta > 0$, on a nécessairement $\|x - y\| = 0$, soit $x = y$. $F$ est donc injective.
			\item Fermé : Soit $(y_k)_{k \in \mathbb{N}}$ une suite de $F(\mathbb{R}^n)$ convergeant vers $y \in \mathbb{R}^n$. Il existe une suite $(x_k)$ telle que $y_k = F(x_k)$. L'inégalité de l'énoncé implique :
			\[ \|x_k - x_p\| \le \frac{1}{\delta} \|F(x_k) - F(x_p)\| = \frac{1}{\delta} \|y_k - y_p\|. \]
			Comme $(y_k)$ converge, elle est de Cauchy. Par l'inégalité ci-dessus, $(x_k)$ est aussi une suite de Cauchy dans $\mathbb{R}^n$. Comme $\mathbb{R}^n$ est complet, $x_k \to x \in \mathbb{R}^n$. $F$ étant continue (car $C^1$), on a $F(x_k) \to F(x)$, d'où $y = F(x)$. Ainsi $y \in F(\mathbb{R}^n)$, donc $F(\mathbb{R}^n)$ est fermé.
		\end{itemize}
		
		\item Inversibilité de la différentielle :
		Soit $a \in \mathbb{R}^n$ et $h \in \mathbb{R}^n$. Par définition de la différentielle :
		\[ F(a+th) = F(a) + D_aF(th) + \|th\|\epsilon(th) = F(a) + t D_aF(h) + t\|h\|\epsilon(th) \text{ quand } t \to 0. \]
		En utilisant l'inégalité de l'énoncé pour $x = a+th$ et $y = a$ :
		\[ \|F(a+th) - F(a)\| \ge \delta \|th\| = \delta |t| \|h\|. \]
		En divisant par $|t| > 0$ et en faisant tendre $t$ vers 0 :
		\[ \left\| D_aF(h) + \|h\|\epsilon(ht) \right\| \ge \delta \|h\| \implies \|D_aF(h)\| \ge \delta \|h\|. \]
		Si $D_aF(h) = 0$, alors $\delta \|h\| \le 0$, donc $h=0$. L'application linéaire $D_aF$ est donc injective. Comme elle va de $\mathbb{R}^n$ dans lui-même (dimension finie), elle est bijective, donc inversible.
		
		\item Difféomorphisme global :
		\begin{itemize}
			\item Ouvert : En tout point $x \in \mathbb{R}^n$, $F$ est de classe $C^1$ et sa différentielle est inversible. D'après le théorème d'inversion locale, $F$ est un difféomorphisme local. En particulier, l'image de tout ouvert est un ouvert. Comme $\mathbb{R}^n$ est ouvert, $F(\mathbb{R}^n)$ est ouvert.
			\item Surjectivité : $F(\mathbb{R}^n)$ est une partie de $\mathbb{R}^n$ non vide, à la fois ouverte et fermée. $\mathbb{R}^n$ étant connexe, les seules parties à la fois ouvertes et fermées sont $\emptyset$ et $\mathbb{R}^n$. Donc $F(\mathbb{R}^n) = \mathbb{R}^n$ et $F$ est surjective.
			\item Conclusion : $F$ est une bijection de classe $C^1$ dont la différentielle est partout inversible. D'après le théorème d'inversion globale, $F$ est un $C^1$ difféomorphisme de $\mathbb{R}^n$ sur $\mathbb{R}^n$.
		\end{itemize}
	\end{enumerate}
	\end{proof}
	
	\setcounter{exercise}{20}
	\begin{exercise}{(Principe du maximum)}
		Soit $\Omega$ un ouvert borné de $\mathbb{R}^n$, et soit $f : \overline{\Omega} \to \mathbb{R}$ une fonction continue sur $\overline{\Omega}$, de classe $C^2$ sur $\Omega$.
		\begin{enumerate}
			\item Montrer que $f$ est majorée et atteint sa borne supérieure.
			\item On suppose que $\Delta f(x) > 0$ pour tout $x \in \Omega$. Montrer que le maximum de $f$ sur $\overline{\Omega}$ ne peut pas être atteint en un point de $\Omega$.
			\item On suppose que $\Delta f(x) \ge 0$ pour tout $x \in \Omega$. Montrer que 
			\[ \max_{\overline{\Omega}} f = \max_{\partial \Omega} f. \]
			On pourra considérer $g(x) = f(x) + \frac{\epsilon}{2}|x|^2$.
			\item Montrer que si $f$ vérifie $\Delta f = 0$ dans $\Omega$ et $f = 0$ sur $\partial \Omega$, alors $f$ est identiquement nulle.
		\end{enumerate}
	\end{exercise}
	
	\begin{proof}
		\begin{enumerate}
			\item L'ensemble $\overline{\Omega}$ est un fermé borné de $\mathbb{R}^n$, c'est donc un compact. Comme la fonction $f$ est continue sur ce compact, le théorème des bornes atteintes assure que $f$ est majorée et qu'elle atteint ses bornes (supérieure et inférieure) en au moins un point de $\overline{\Omega}$.
			
			\item Supposons par l'absurde que $f$ atteigne son maximum en un point $x_0 \in \Omega$. Comme $\Omega$ est ouvert et $f$ est $C^2$, les conditions nécessaires d'optimalité du second ordre s'appliquent :
			\begin{itemize}
				\item Le gradient est nul : $\nabla f(x_0) = 0$.
				\item La matrice Hessienne $H_f(x_0)$ est symétrique négative (ses valeurs propres sont $\le 0$).
			\end{itemize}
			Or, le Laplacien est la trace de la matrice Hessienne : $\Delta f(x_0) = \text{tr}(H_f(x_0))$. La trace d'une matrice symétrique négative est nécessairement inférieure ou égale à $0$. Cela contredit l'hypothèse $\Delta f(x_0) > 0$. Le maximum est donc nécessairement atteint sur le bord $\partial \Omega$.
			
			\item Soit $\epsilon > 0$. Posons $g(x) = f(x) + \frac{\epsilon}{2n} |x|^2$ (en adaptant l'indication pour simplifier le calcul). On a :
			\[ \Delta g(x) = \Delta f(x) + \frac{\epsilon}{2n} \Delta(|x|^2) = \Delta f(x) + \frac{\epsilon}{2n} \cdot (2n) = \Delta f(x) + \epsilon. \]
			Comme $\Delta f \ge 0$, on a $\Delta g(x) \ge \epsilon > 0$. D'après la question 2, le maximum de $g$ sur $\overline{\Omega}$ est atteint sur $\partial \Omega$ :
			\[ \forall x \in \overline{\Omega}, \quad f(x) \le g(x) \le \max_{\partial \Omega} g = \max_{y \in \partial \Omega} \left( f(y) + \frac{\epsilon}{2n}|y|^2 \right) \]
			Soit $R = \max_{y \in \partial \Omega} |y|$. On a $f(x) \le \max_{\partial \Omega} f + \frac{\epsilon R^2}{2n}$. En faisant tendre $\epsilon$ vers $0$, on obtient $f(x) \le \max_{\partial \Omega} f$ pour tout $x$, d'où l'égalité des maximums.
			
			\item \begin{itemize}
				\item Comme $\Delta f \ge 0$, le principe du maximum (Q3) donne : $\forall x \in \Omega, f(x) \le \max_{\partial \Omega} f = 0$.
				\item En considérant $-f$, on a $\Delta(-f) = -\Delta f = 0 \ge 0$. Le principe du maximum appliqué à $-f$ donne : $\forall x \in \Omega, -f(x) \le \max_{\partial \Omega} (-f) = 0$, soit $f(x) \ge 0$.
			\end{itemize}
			Ainsi, pour tout $x \in \Omega$, $0 \le f(x) \le 0$, donc $f$ est identiquement nulle.
		\end{enumerate}
	\end{proof}
	
	\section{Équations différentielles}
	\setcounter{exercise}{0}
	\begin{exercise}
		Résoudre les équations différentielles suivantes :
		\begin{enumerate}
			\item $y'(t) = t^2y(t) + t^2$, avec $y(0) = 1$.
			\item $y''(t) + y'(t) + y(t) = 0$, avec $y(0) = 0, y'(0) = 1$.
			\item $y'(t) = A y(t)$, avec $A = \begin{pmatrix} 2 & 1 & 0 \\ 0 & 2 & 1 \\ 0 & 0 & 2 \end{pmatrix}$ et $y(0) = \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}$.
			\item $y'(t) + e^{t-y(t)} = 0$, avec $y(0) = 0$.
		\end{enumerate}
	\end{exercise}
	
	\begin{proof}
		\begin{enumerate}
			\item L'équation est $y'(t) - t^2y(t) = t^2$. C'est une équation linéaire du premier ordre.
			\begin{itemize}
				\item {Solution homogène :} $y_h'(t) = t^2 y_h(t)$. Une primitive de $t^2$ est $\frac{t^3}{3}$. Donc $y_h(t) = C e^{t^3/3}$.
				\item {Solution particulière :} On remarque la solution constante $y_p(t) = -1$ car $y_p' = 0$ et $t^2(-1) + t^2 = 0$.
				\item {Solution générale :} $y(t) = C e^{t^3/3} - 1$.
				\item {Condition initiale :} $y(0) = 1 \implies C e^{0} - 1 = 1 \implies C = 2$.
			\end{itemize}
			La solution est \textbf{$y(t) = 2e^{t^3/3} - 1$}.
			\item L'équation caractéristique est $r^2 + r + 1 = 0$. Le discriminant est $\Delta = 1^2 - 4 = -3 = (i\sqrt{3})^2$.
			Les racines sont $r = -\frac{1}{2} \pm i\frac{\sqrt{3}}{2}$.
			La forme générale est $y(t) = e^{-t/2} \left[ A \cos\left(\frac{\sqrt{3}}{2}t\right) + B \sin\left(\frac{\sqrt{3}}{2}t\right) \right]$.
			\begin{itemize}
				\item $y(0) = 0 \implies A = 0$. Donc $y(t) = B e^{-t/2} \sin\left(\frac{\sqrt{3}}{2}t\right)$.
				\item $y'(t) = B e^{-t/2} \left[ -\frac{1}{2}\sin\left(\frac{\sqrt{3}}{2}t\right) + \frac{\sqrt{3}}{2}\cos\left(\frac{\sqrt{3}}{2}t\right) \right]$.
				\item $y'(0) = 1 \implies B \cdot \frac{\sqrt{3}}{2} = 1 \implies B = \frac{2}{\sqrt{3}}$.
			\end{itemize}
			La solution est \textbf{$y(t) = \frac{2}{\sqrt{3}} e^{-t/2} \sin\left(\frac{\sqrt{3}}{2}t\right)$}.
			
			\item Le système est $y'(t) = Ay(t)$. La solution est $y(t) = e^{tA}y(0)$.
			On décompose $A = 2I + N$ avec $N = \begin{pmatrix} 0 & 1 & 0 \\ 0 & 0 & 1 \\ 0 & 0 & 0 \end{pmatrix}$. Comme $2I$ et $N$ commutent : $e^{tA} = e^{2tI}e^{tN} = e^{2t} e^{tN}$.
			$N^2 = \begin{pmatrix} 0 & 0 & 1 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{pmatrix}$ et $N^3 = 0$.
			Donc $e^{tN} = I + tN + \frac{t^2}{2}N^2 = \begin{pmatrix} 1 & t & t^2/2 \\ 0 & 1 & t \\ 0 & 0 & 1 \end{pmatrix}$.
			Le vecteur solution est $y(t) = e^{2t} \begin{pmatrix} 1 & t & t^2/2 \\ 0 & 1 & t \\ 0 & 0 & 1 \end{pmatrix} \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}$.
			D'où \textbf{$y(t) = e^{2t} \begin{pmatrix} 1 + t + \frac{t^2}{2} \\ 1 + t \\ 1 \end{pmatrix}$}.
			
			\item L'équation est $y'(t) = -e^t e^{-y(t)}$, ce qui s'écrit $e^{y(t)} y'(t) = -e^t$.
			En intégrant par rapport à $t$ : $\int e^{y} dy = \int -e^t dt$.
			On obtient $e^{y(t)} = -e^t + C$.
			Condition initiale : $y(0) = 0 \implies e^0 = -e^0 + C \implies 1 = -1 + C \implies C = 2$.
			Ainsi $e^{y(t)} = 2 - e^t$. En passant au logarithme :
			La solution est \textbf{$y(t) = \ln(2 - e^t)$}, définie pour $t < \ln(2)$.
		\end{enumerate}
	\end{proof}
	
	
	\setcounter{exercise}{2}
	\begin{exercise}
		Résoudre le problème différentiel suivant sur $\mathbb{R}$\\
		\[2x²y'=1-y²\]
	\end{exercise}
	
	\begin{proof}
		\begin{itemize}
			\item On travaille sur $I\subset \mathbb{R}$. Posons $f(x,y)=\frac{1-y²}{2x²}$. $f$ est :\\
			\begin{itemize}
				\item continue sur $I\times \mathbb{R}$
				\item $\mathcal{C}¹$ en $y$ donc localement lipschitzienne en $y$
			\end{itemize}
			Par le théorème de Cauchy Lipschitz, pour tout $(x_0,y_0)$, il existe une unique solution définie sur $I$.
		\end{itemize}
	\end{proof}
	
	\setcounter{exercise}{5}
	\begin{exercise}
		\textbf{Exercice 6.} Soit une fonction continue $A : \mathbb{R} \to M_n(\mathbb{R})$. On note $(y_1,\dots,y_n)$ une base de solutions de l’équation différentielle
		\[
		y'(t)=A(t)y(t), \qquad t\in\mathbb{R}.
		\]
		On notera aussi $M(t)$ la matrice $(y_1(t),\dots,y_n(t))$ dans la base canonique de $\mathbb{R}^n$.
		\begin{enumerate}
			\item Calculer le wronskien $W(t)=\det M(t)$, pour tout $t\in\mathbb{R}$.
			\item On suppose maintenant que $\|A(\cdot)\|$ est intégrable sur $\mathbb{R}_+$.
			\begin{enumerate}
				\item Montrer que toute solution $y$ admet une limite en $+\infty$.
				\item Soit $\theta$ l’application qui à $y_0\in\mathbb{R}^n$ associe la limite en $+\infty$ de la solution $y$ telle que $y(0)=y_0$. Montrer que $\theta$ est un isomorphisme de $\mathbb{R}^n$ sur $\mathbb{R}^n$.
			\end{enumerate}
		\end{enumerate}
		\end{exercise}
		
		\begin{proof}
		
		
		1. La matrice fondamentale $M(t)$ vérifie
		\[
		M'(t)=A(t)M(t).
		\]
		On pose $W(t)=\det M(t)$. Par la formule de dérivation du déterminant,
		\[
		W'(t)=\operatorname{tr}(A(t))\,W(t).
		\]
		On obtient donc une équation différentielle scalaire :
		\[
		W'(t)=\operatorname{tr}(A(t))\,W(t).
		\]
		En intégrant,
		\[
		W(t)=W(0)\exp\!\left(\int_0^t \operatorname{tr}(A(s))\,ds\right).
		\]
		En particulier, si $(y_1,\dots,y_n)$ est une base de solutions, alors $W(0)\neq 0$, donc
		\[
		W(t)\neq 0 \quad \text{pour tout } t\in\mathbb{R}.
		\]
		
		2.a) Soit $y$ une solution. Elle vérifie
		\[
		y(t)=y(0)+\int_0^t A(s)y(s)\,ds.
		\]
		Pour $t\ge s\ge 0$,
		\[
		y(t)-y(s)=\int_s^t A(\tau)y(\tau)\,d\tau.
		\]
		On en déduit
		\[
		\|y(t)-y(s)\|
		\le
		\int_s^t \|A(\tau)\|\,\|y(\tau)\|\,d\tau.
		\]
		Par ailleurs on a également,
		\[\|y(t)\|\leq \|y(0)\| + \int_{0}^{t}\|A(s)y(s)\|ds\]
		Donc en appliquant le lemme de Gronwall pour $\|A(\cdot)\|$ positive et $\|y(\cdot)\|$ continue, pour $t\ge 0$,
		\[
		\|y(t)\|
		\le
		\|y(0)\|\exp\!\left(\int_0^t \|A(\sigma)\|\,d\sigma\right).
		\]
		Comme $\|A(\cdot)\|$ est intégrable sur $\mathbb{R}_+$, la quantité
		\[
		C=\exp\!\left(\int_0^{+\infty} \|A(\sigma)\|\,d\sigma\right)
		\]
		est finie, et donc
		\[
		\|y(t)\|\le C\|y(0)\| \quad \text{pour tout } t\ge 0.
		\]
		Ainsi $y$ est bornée sur $\mathbb{R}_+$.
		
		Dès lors,
		\[
		\|y(t)-y(s)\|
		\le
		C\|y(0)\|\int_s^t \|A(\tau)\|\,d\tau.
		\]
		Comme $\|A\|$ est intégrable sur $\mathbb{R}_+$, le membre de droite tend vers $0$ lorsque $s,t\to+\infty$.  
		
		Donc $y(t)$ est de Cauchy lorsque $t\to+\infty$, et comme $\mathbb{R}^n$ est complet, $y(t)$ admet une limite lorsque $t\to+\infty$.\\
		
		2.b) On définit
		\[
		\theta : \mathbb{R}^n \to \mathbb{R}^n,
		\qquad
		\theta(y_0)=\lim_{t\to+\infty} y(t),
		\]
		où $y$ est l’unique solution telle que $y(0)=y_0$.
		
		D'après la question précédente, $\theta$ est bien définie. Elle est linéaire car l’équation différentielle est linéaire.
		
		Montrons qu’elle est injective.  
		
		Si $\theta(y_0)=0$, alors $y(t)\to 0$ lorsque $t\to+\infty$.  
		On écrit, pour $t\ge 0$,
		\[
		y(t)=y(T)-\int_t^T A(s)y(s)\,ds.
		\]
		En faisant tendre $T\to+\infty$ et en utilisant que $y(T)\to 0$, on obtient
		\[
		y(t)=-\int_t^{+\infty} A(s)y(s)\,ds.
		\]
		On en déduit
		\[
		\|y(t)\|
		\le
		\int_t^{+\infty} \|A(s)\|\,\|y(s)\|\,ds.
		\]
		En posant
		\[
		m(t)=\sup_{u\ge t}\|y(u)\|,
		\]
		qui est bien défini car $\|y(\cdot)\|$ est continue et $y(t)\rightarrow 0$ en $+\infty$, on obtient
		\[
		m(t)\le m(t)\int_t^{+\infty}\|A(s)\|\,ds.
		\]
		Et comme $\|A(\cdot)\|$ est intégrable, on a pour $t$ assez grand,
		\[
		\int_t^{+\infty}\|A(s)\|\,ds<1,
		\]
		donc nécessairement $m(t)=0$. Ainsi $y(t)=0$ pour $t$ assez grand, puis par unicité des solutions, $y\equiv 0$. Donc $y_0=0$.
		
		Ainsi $\theta$ est injective.  
		
		Comme $\theta$ est linéaire entre deux espaces vectoriels de même dimension finie $n$, elle est bijective.  
		
		Donc $\theta$ est un isomorphisme de $\mathbb{R}^n$ sur $\mathbb{R}^n$.
		
	
	\end{proof}
	
	
\end{document}
