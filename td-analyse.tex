\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{enumitem}
\usepackage{geometry}
\usepackage{graphicx}
\geometry{a4paper, margin=1.5cm}


\title{\Large \textbf{TD Analyse}}
\author{Thomas Goossaert-Cosyn}

\newtheoremstyle{exercisestyle}
{}                % Espace avant
{}                % Espace après
{\normalfont}  % Police du titre (gras)
{}                % Indentation
{\bfseries}       % Police du titre de l'énoncé (gras)
{.}               % Ponctuation après le titre
{ }               % Espace après le titre
{}                % Style du corps (par défaut)
\theoremstyle{exercisestyle}
\newtheorem{exercise}{Exercice}

% Alignement des puces à gauche et espacement réduit
\setlist[itemize]{leftmargin=*, itemsep=0.3em}

\let\oldsection\section
\renewcommand{\section}{\clearpage\oldsection}



\begin{document}
	\maketitle
	
	\setcounter{section}{1}
	\section{Fonctions d'une variable réelle}
	
	\setcounter{exercise}{23}
	\begin{exercise}
		Soit $f$ une fonction réelle définie sur un intervalle ouvert $I$. On suppose que pour tout $x \in I$ on a
		\[
		\liminf_{h \to 0^+} \frac{f(x+h) + f(x-h) - 2f(x)}{2h} > 0.
		\]
		Montrer que $f$ est convexe sur $I$.
		
		Le résultat reste vrai si on suppose seulement que la $\liminf$ est $\geq 0$. Voyez-vous comment faire ?
	\end{exercise}
	
	\begin{proof}
		Posons les fonctions pentes
		\[s_+(x,h)=\frac{f(x+h)-f(x)}{h}, s_-(x,h)=\frac{f(x)-f(x-h)}{h}\]
		L'hypothèse de l'énoncé se réécrit alors
		\[\forall x\in I, \liminf_{h\rightarrow 0^{+}} s_+(x,h)-s_-(x,h) > 0\]
		Pour passer de cette propriété locale à une inégalité globale, considérons $[a,c]\subset I$ et $[x_0=a,...,x_n=c]$ une subdivision de pas $\Delta=\frac{c-a}{n}$.\\
		On définit la suite de pentes locales par :
		\[s_k=\frac{f(x_{k+1})-f(x_k)}{\Delta}\]
		L'hypothèse donne don que $s_0<s_1<...<s_{n-1}$\\
		Soit $b\in [a,c]$, $n$ suffisamment grand et $k$ tel que $x_k\leq b<x_{k+1}$, alors la croissance des pentes entraine
		\[\frac{f(b)-f(a)}{b-a}\leq s_k<\frac{f(c)-f(b)}{c-b}\]
		D'où la convexité de $f$.
	\end{proof}
	
	\setcounter{section}{3}
	\section{Topologie}
	
	\setcounter{exercise}{2}
	\begin{exercise}
		Soit $K, L$ deux espaces métriques compact et $\pi : K \rightarrow L$ une bijection continue.\\
		Montrer que $\pi$ est un homéomorphisme entre $K$ et $L$
	\end{exercise}
	\begin{proof}
		Pour prouver que $\pi$ est un homéomorphisme, il suffit de montrer que sa réciproque $\pi^{-1} : L \rightarrow K$ est continue.\\
		
		Soit $(y_n)_{n \in \mathbb{N}}$ une suite d'éléments de $L$ convergeant vers un élément $y \in L$. Posons :
		\[ x_n = \pi^{-1}(y_n) \quad \text{et} \quad x = \pi^{-1}(y) \]
		Montrons que la suite $(x_n)$ converge vers $x$ dans $K$.
		
		La suite $(x_n)$ est une suite d'éléments de l'espace métrique compact $K$. 
		Par Bolzano-Weierstrass, de toute suite d'un compact, on peut extraire une sous-suite convergente. Soit $(x_{\phi(n)})$ une telle sous-suite, et notons $z \in K$ sa limite :
		\[ x_{\phi(n)} \xrightarrow[n \to \infty]{} z \]
		
		L'application $\pi$ est continue sur $K$. Par caractérisation séquentielle de la continuité, l'image de la sous-suite doit converger vers l'image de sa limite :
		\[ \pi(x_{\phi(n)}) \xrightarrow[n \to \infty]{} \pi(z) \]
		Or, par construction, $\pi(x_{\phi(n)}) = y_{\phi(n)}$. 
		
		Comme la suite parente $(y_n)$ converge vers $y$, toute sous-suite extraite converge également vers $y$. On a donc, par unicité de la limite dans $L$ :
		\[ \pi(z) = y \]
		Puisque $\pi$ est une bijection, chaque élément possède un unique antécédent. Sachant que $\pi(x) = y$, l'injectivité de $\pi$ impose :
		\[ z = x \]
		
		Nous avons montré que toute sous-suite convergente de $(x_n)$ converge nécessairement vers $x$. Dans un espace compact, si une suite possède une unique valeur d'adhérence, alors elle converge vers cette valeur.
		
		Ainsi, $x_n \xrightarrow[n \to \infty]{} x$, ce qui prouve que $\pi^{-1}$ est continue en tout point $y \in L$. 
		
		Conclusion : $\pi$ est une bijection continue dont la réciproque est continue, c'est donc un homéomorphisme.
	\end{proof}
	

	\section{Intégration}
	
	\setcounter{exercise}{3}
	\begin{exercise}
		On travaille avec la mesure de Lebesgue sur $\mathbb{R}$ et on se donne une fonction continue par morceaux (par exemple) sur $\mathbb{R}$.
		
		\textbf{(1)} Montrer que si $f$ est positive, on a, lorsque $R \to +\infty$,
		\[
		\int_{-R}^{R} f \longrightarrow \int_{\mathbb{R}} f .
		\]
		
		\textbf{(2)} Montrer que si $f$ est intégrable, on a, lorsque $R \to +\infty$,
		\[
		\int_{-R}^{R} f \longrightarrow \int_{\mathbb{R}} f .
		\]
		
		\textbf{(3)} On suppose $f$ intégrable sur $\mathbb{R}$. Montrer que pour tout $\varepsilon > 0$, on peut trouver $g$ intégrable, bornée et à support compact telle que
		\[
		\int_{\mathbb{R}} |f-g| \le \varepsilon .
		\]
	\end{exercise}
		
		\begin{proof}
			\textbf{(1)}
			Supposons $f$ mesurable positive. Pour $R>0$, posons
			\[
			f_R = f \mathbf{1}_{[-R,R]}.
			\]
			Alors $(f_R)_{R>0}$ est une famille croissante de fonctions mesurables positives et
			\[
			f_R(x) \uparrow f(x) \quad \text{pour tout } x \in \mathbb{R}.
			\]
			Par le théorème de convergence monotone,
			\[
			\lim_{R \to +\infty} \int_{\mathbb{R}} f_R
			=
			\int_{\mathbb{R}} \lim_{R\to+\infty} f_R
			=
			\int_{\mathbb{R}} f.
			\]
			Or
			\[
			\int_{\mathbb{R}} f_R
			=
			\int_{-R}^{R} f.
			\]
			On en déduit
			\[
			\int_{-R}^{R} f \longrightarrow \int_{\mathbb{R}} f.
			\]
			
			\textbf{(2)} Supposons maintenant $f \in L^1(\mathbb{R})$. Alors $|f|$ est intégrable. On applique le résultat précédent à la fonction positive $|f|$ :
			\[
			\int_{-R}^{R} |f| \longrightarrow \int_{\mathbb{R}} |f|.
			\]
			On écrit
			\[
			\int_{\mathbb{R}} f - \int_{-R}^{R} f
			=
			\int_{|x|>R} f(x)\,dx.
			\]
			Donc
			\[
			\left| \int_{\mathbb{R}} f - \int_{-R}^{R} f \right|
			\le
			\int_{|x|>R} |f|.
			\]
			Or
			\[
			\int_{|x|>R} |f|
			=
			\int_{\mathbb{R}} |f| - \int_{-R}^{R} |f|
			\longrightarrow 0.
			\]
			Ainsi
			\[
			\int_{-R}^{R} f \longrightarrow \int_{\mathbb{R}} f.
			\]
			
			\textbf{(3)} Soit $f \in L^1(\mathbb{R})$ et $\varepsilon > 0$.
			
			
			\textbf{Étape 1 : troncature du support.}
			
			D'après le point (2), il existe $R>0$ tel que
			\[
			\int_{|x|>R} |f(x)|\,dx < \frac{\varepsilon}{2}.
			\]
			Posons
			\[
			f_1 = f \mathbf{1}_{[-R,R]}.
			\]
			Alors
			\[
			\int_{\mathbb{R}} |f-f_1|
			=
			\int_{|x|>R} |f|
			<
			\frac{\varepsilon}{2}.
			\]
			
			
			\textbf{Étape 2 : troncature des valeurs.}
			
			Pour $M>0$, posons
			\[
			f_{1,M}(x) =
			\begin{cases}
				f_1(x) & \text{si } |f_1(x)| \le M, \\
				M\,\mathrm{sgn}(f_1(x)) & \text{sinon}.
			\end{cases}
			\]
			Alors $f_{1,M}$ est bornée par $M$ et a toujours son support dans $[-R,R]$.
			
			Comme $f_1 \in L^1$, on a
			\[
			\int_{\{|f_1|>M\}} |f_1| \longrightarrow 0
			\quad \text{lorsque } M \to +\infty.
			\]
			Donc il existe $M>0$ tel que
			\[
			\int_{\{|f_1|>M\}} |f_1|
			<
			\frac{\varepsilon}{2}.
			\]
			Or
			\[
			|f_1 - f_{1,M}|
			\le
			|f_1| \mathbf{1}_{\{|f_1|>M\}},
			\]
			donc
			\[
			\int_{\mathbb{R}} |f_1 - f_{1,M}|
			<
			\frac{\varepsilon}{2}.
			\]
			
			\medskip
			
			\textbf{Conclusion.}
			
			Posons $g = f_{1,M}$. Alors $g$ est intégrable, bornée, à support compact et
			\[
			\int_{\mathbb{R}} |f-g|
			\le
			\int_{\mathbb{R}} |f-f_1|
			+
			\int_{\mathbb{R}} |f_1-g|
			<
			\frac{\varepsilon}{2}
			+
			\frac{\varepsilon}{2}
			=
			\varepsilon.
			\]
			
			\bigskip
			
			Ceci achève la démonstration.
		\end{proof}
	
	\setcounter{section}{6}
	\section{Séries de Fourier}
	
	\setcounter{exercise}{5}
	\begin{exercise}{(Critère d'équirépartition)}
		On se donne une suite $(x_n)$ de réels telle que
		\[ \forall k \in \mathbb{Z} \setminus \{0\}, \qquad \lim_{N \to +\infty} \frac{1}{N} \sum_{n=1}^N e^{ikx_n} = 0. \]
		Montrer que pour toute fonction $f$ continue $2\pi$-périodique on a
		\[ \lim_{N \to +\infty} \frac{1}{N} \sum_{n=1}^N f(x_n) = \frac{1}{2\pi} \int_0^{2\pi} f(t) dt. \]
	\end{exercise}
	
	\begin{proof}
		Étape 1 : Cas des polynômes trigonométriques \\
		Soit $P$ un polynôme trigonométrique. Par définition, il existe un entier $M \geq 0$ et des coefficients complexes $(c_k)_{-M \leq k \leq M}$ tels que pour tout $x \in \mathbb{R}$,
		\[ P(x) = \sum_{k=-M}^M c_k e^{ikx}. \]
		Calculons la moyenne de $P$ sur les $N$ premiers termes de la suite $(x_n)$ :
		\[ \frac{1}{N} \sum_{n=1}^N P(x_n) = \frac{1}{N} \sum_{n=1}^N \sum_{k=-M}^M c_k e^{ikx_n} = \sum_{k=-M}^M c_k \left( \frac{1}{N} \sum_{n=1}^N e^{ikx_n} \right). \]
		Par hypothèse, pour tout $k \neq 0$, on a $\lim_{N \to +\infty} \frac{1}{N} \sum_{n=1}^N e^{ikx_n} = 0$. 
		Pour $k = 0$, la moyenne vaut exactement $1$ quel que soit $N$. Par linéarité de la limite (la somme étant finie), on obtient :
		\[ \lim_{N \to +\infty} \frac{1}{N} \sum_{n=1}^N P(x_n) = c_0. \]
		Par ailleurs, calculons l'intégrale de $P$ sur une période :
		\[ \frac{1}{2\pi} \int_0^{2\pi} P(t) dt = \sum_{k=-M}^M c_k \left( \frac{1}{2\pi} \int_0^{2\pi} e^{ikt} dt \right) = c_0, \]
		car l'intégrale de $e^{ikt}$ sur $[0, 2\pi]$ est nulle pour $k \neq 0$, et vaut $2\pi$ pour $k = 0$.
		Le résultat est donc vérifié pour tout polynôme trigonométrique.\\
		
		Étape 2 : Généralisation aux fonctions continues par densité\\
		Soit $f$ une fonction continue et $2\pi$-périodique sur $\mathbb{R}$, et soit $\varepsilon > 0$.
		D'après le théorème d'approximation de Weierstrass trigonométrique (ou théorème de Stone-Weierstrass), il existe un polynôme trigonométrique $P$ tel que $\|f - P\|_\infty \leq \varepsilon$, où $\| \cdot \|_\infty$ désigne la norme de la convergence uniforme sur $\mathbb{R}$.
		
		Majorons la différence qui nous intéresse en insérant judicieusement le polynôme $P$ et en utilisant l'inégalité triangulaire :
		\begin{align*}
			\Delta_N &= \left| \frac{1}{N} \sum_{n=1}^N f(x_n) - \frac{1}{2\pi} \int_0^{2\pi} f(t) dt \right| \\
			&\leq \underbrace{\left| \frac{1}{N} \sum_{n=1}^N (f(x_n) - P(x_n)) \right|}_{A_N} 
			+ \underbrace{\left| \frac{1}{N} \sum_{n=1}^N P(x_n) - \frac{1}{2\pi} \int_0^{2\pi} P(t) dt \right|}_{B_N} 
			+ \underbrace{\left| \frac{1}{2\pi} \int_0^{2\pi} (P(t) - f(t)) dt \right|}_{C}
		\end{align*}
		
		Majorons chaque terme :
		\begin{enumerate}
			\item Le terme $A_N$ : $\displaystyle A_N \leq \frac{1}{N} \sum_{n=1}^N |f(x_n) - P(x_n)| \leq \frac{1}{N} \sum_{n=1}^N \|f - P\|_\infty \leq \varepsilon$.
			\item Le terme $C$ : $\displaystyle C \leq \frac{1}{2\pi} \int_0^{2\pi} |P(t) - f(t)| dt \leq \frac{1}{2\pi} \int_0^{2\pi} \|P - f\|_\infty dt \leq \varepsilon$.
			\item Le terme $B_N$ : Puisque le résultat a été démontré à l'étape 1 pour le polynôme $P$, on sait que $B_N \xrightarrow[N \to +\infty]{} 0$. Il existe donc un entier $N_0$ tel que pour tout $N \geq N_0$, on ait $B_N \leq \varepsilon$.
		\end{enumerate}
		
		En regroupant ces majorations, on obtient que pour tout $N \geq N_0$ :
		\[ \Delta_N \leq \varepsilon + \varepsilon + \varepsilon = 3\varepsilon. \]
	\end{proof}
	
	\section{Transformée de Fourier}
	
	\setcounter{exercise}{4}
	\begin{exercise}{(Polynômes et fonctions de Hermite)}
		On travaille dans l'espace de Hilbert $H = L^2(\mathbb{R}, \mu)$ associé à la mesure (gaussienne standard) de probabilité $\mu$ sur $\mathbb{R}$ définie par $d\mu(x) = \frac{e^{-x^2/2}}{\sqrt{2\pi}}dx$. Pour $n \in \mathbb{N}$ et $x \in \mathbb{R}$, on note :
		\[ h_n(x) = e^{x^2/2}g^{(n)}(x), \quad \text{où} \quad g(x) = e^{-x^2/2}. \]
		
		\begin{enumerate}
			\item Montrer que les fonctions $h_n$ sont polynomiales. Déterminer leurs degrés et coefficients dominants.
			\item Montrer que $(h_n)_{n\in\mathbb{N}}$ forme une famille orthogonale de $H$ et calculer la norme $\lambda_n$ de chaque élément $h_n$.
			\item On veut montrer que la famille $(\lambda_n^{-1}h_n)_{n\in\mathbb{N}}$ est une base hilbertienne de $H$.
			\begin{enumerate}
				\item Expliquer pourquoi il suffit de montrer que les polynômes sont denses dans $H$.
				\item Pour $f \in H$ et $x \in \mathbb{R}$, on note $\psi_f(x) = f(x)e^{-x^2/2}$. Montrer que sa transformée de Fourier $\widehat{\psi_f}$ est bien définie sur $\mathbb{R}$ et qu'elle s'étend en une fonction holomorphe sur $\mathbb{C}$.
				\item Pour tout $n \in \mathbb{N}$, calculer la dérivée $n$-ième $\widehat{\psi_f}^{(n)}(0)$. En déduire que si $f$ est orthogonale à tous les polynômes, alors $f$ est nulle.
				\item Conclure.
			\end{enumerate}
		\end{enumerate}
	\end{exercise}
	
	\begin{proof}
		1. Par récurrence, montrons que $g^{(n)}(x) = P_n(x)e^{-x^2/2}$ où $P_n$ est un polynôme de degré $n$ et de coefficient dominant $(-1)^n$.
		\begin{itemize}
			\item Pour $n=0$, $g^{(0)}(x) = e^{-x^2/2}$, donc $P_0(x)=1$. La propriété est vraie.
			\item Supposons $g^{(n)}(x) = P_n(x)e^{-x^2/2}$. Alors :
			\[ g^{(n+1)}(x) = \frac{d}{dx}(P_n(x)e^{-x^2/2}) = (P_n'(x) - x P_n(x))e^{-x^2/2} \]
			Ainsi $P_{n+1}(x) = P_n'(x) - x P_n(x)$. Si $P_n$ est de degré $n$ et de coefficient dominant $a_n$, alors $-xP_n$ est de degré $n+1$ et de coefficient dominant $-a_n$. Le terme $P_n'$ est de degré $n-1$, il ne modifie pas le degré dominant.
		\end{itemize}
		Par construction, $h_n(x) = e^{x^2/2} (P_n(x)e^{-x^2/2}) = P_n(x)$. 
		\textbf{Conclusion :} $h_n$ est un polynôme de \textbf{degré $n$} et de \textbf{coefficient dominant $(-1)^n$}.\\
		
		2. Soient $m, n \in \mathbb{N}$ avec $m < n$. Le produit scalaire dans $H$ est :
		\[ \langle h_n, h_m \rangle_\mu = \int_{\mathbb{R}} h_n(x) h_m(x) \frac{e^{-x^2/2}}{\sqrt{2\pi}} dx = \frac{1}{\sqrt{2\pi}} \int_{\mathbb{R}} \left( e^{x^2/2} g^{(n)}(x) \right) h_m(x) e^{-x^2/2} dx = \frac{1}{\sqrt{2\pi}} \int_{\mathbb{R}} g^{(n)}(x) h_m(x) dx \]
		Par intégrations par parties successives ($n$ fois), les termes de bord s'annulent car les dérivées de la gaussienne tendent vers $0$ :
		\[ \langle h_n, h_m \rangle_\mu = \frac{(-1)^n}{\sqrt{2\pi}} \int_{\mathbb{R}} g(x) h_m^{(n)}(x) dx \]
		Comme $\deg(h_m) = m < n$, on a $h_m^{(n)}(x) = 0$, donc $\langle h_n, h_m \rangle_\mu = 0$. La famille est orthogonale.
		
		Pour la norme $\lambda_n^2 = \langle h_n, h_n \rangle_\mu$ :
		\[ \lambda_n^2 = \frac{(-1)^n}{\sqrt{2\pi}} \int_{\mathbb{R}} g(x) h_n^{(n)}(x) dx \]
		Or $h_n(x) = (-1)^n x^n + \dots$, donc $h_n^{(n)}(x) = (-1)^n n!$. D'où :
		\[ \lambda_n^2 = \frac{(-1)^n (-1)^n n!}{\sqrt{2\pi}} \int_{\mathbb{R}} e^{-x^2/2} dx = \frac{n!}{\sqrt{2\pi}} \times \sqrt{2\pi} = n! \]
		\textbf{Conclusion :} $\lambda_n = \sqrt{n!}$.\\
		
		3.a) Puisque $\deg(h_n) = n$, toute combinaison linéaire des $h_k$ ($k \le n$) décrit l'espace des polynômes de degré au plus $n$. Si les polynômes sont denses dans $H$, alors l'adhérence de $\text{Vect}(h_n)_{n\in\mathbb{N}}$ est $H$. Comme la famille est orthonormale (après division par $\lambda_n$), c'est une base hilbertienne.\\
		
		3.b) $f \in H$ signifie $\int |f|^2 d\mu < \infty$. $\psi_f(x) = f(x)e^{-x^2/2}$.\\
		Par Cauchy-Schwarz, sa transformée de Fourier $\widehat{\psi_f}(\xi) = \int f(x) e^{-x^2/2} e^{-ix\xi} dx$ est bien définie car $\psi_f \in L^1(\mathbb{R})$ :
		\[ \int |f(x)| e^{-x^2/2} dx = \sqrt{2\pi} \int |f(x)| e^{-x^2/4} \frac{e^{-x^2/4}}{\sqrt{2\pi}} dx \le \sqrt{2\pi} \|f\|_H \|e^{-x^2/4}\|_H < \infty \]
		L'extension holomorphe $F(z) = \int f(x) e^{-x^2/2} e^{-ixz} dx$ pour $z \in \mathbb{C}$ est justifiée par le fait que pour $z = u+iv$, $|e^{-ixz}| = e^{xv}$. Le terme $e^{-x^2/2}$ assure la convergence et la domination pour tout $z \in \mathbb{C}$ (croissance exponentielle vs décroissance gaussienne).\\
		
		3.c) On a 
		\[\widehat{\psi_f}^{(n)}(0) = \int f(x) e^{-x^2/2} (-ix)^n dx = (-i)^n \sqrt{2\pi} \int f(x) x^n \frac{e^{-x^2/2}}{\sqrt{2\pi}} dx = (-i)^n \sqrt{2\pi} \langle f, x^n \rangle_\mu\]
		Si $f$ est orthogonale à tous les polynômes, alors $\langle f, x^n \rangle_\mu = 0$ pour tout $n$, donc $\widehat{\psi_f}^{(n)}(0) = 0$.
		Comme $\widehat{\psi_f}$ est une fonction analytique (holomorphe sur $\mathbb{C}$), ses coefficients de Taylor en 0 sont tous nuls, donc $\widehat{\psi_f} \equiv 0$. Par injectivité de la transformée de Fourier, $\psi_f = 0$ p.p., donc $f = 0$ p.p.\\
		
		3.d) L'orthogonal de l'espace des polynômes est $\{0\}$, donc les polynômes sont denses dans $H$. La famille $(\lambda_n^{-1} h_n)$ est donc une base hilbertienne.
	\end{proof}
	
	\begin{exercise}{(Échantillonnage de Shannon)}
		On montre que les signaux à bande limitée peuvent se reconstruire à partir de la donnée d'une suite de valeurs. Formellement, on s'intéresse aux fonctions dont la transformée de Fourier est à support compact.
		
		\begin{enumerate}
			\item Soit \( f \in L^1(\mathbb{R}) \) tel que (sans perte de généralité) \( \hat{f}(x) = 0 \) pour tout \( |x| > \pi \).
			\begin{enumerate}
				\item Rappeler pourquoi \( f \) admet un représentant continu, qui est en fait \( C^\infty \), sur \( \mathbb{R} \) et que pour tout \( t \in \mathbb{R} \),
				\[
				f(t) = \frac{1}{\sqrt{2\pi}} \int_{-\pi}^{\pi} \hat{f}(x) e^{ixt} dx.
				\]
				\item \textbf{Heuristique} = à ne pas mettre sur une copie. Sans chercher à justifier les calculs, montrer que :
				\[
				\hat{f}(x) = \sqrt{2\pi} \sum_{k \in \mathbb{Z}} f(k) e^{-2i\pi kx},
				\]
				(On pourra considérer la fonction \( 2\pi \)-périodique \( g \) qui vaut \( g(x) = \hat{f}(x) \) sur \( [-\pi, \pi] \) puis que
				\[
				f(t) = \sqrt{2\pi} \sum_{k \in \mathbb{Z}} f(k) \frac{\sin(\pi(t-k))}{\pi(t-k)}.
				\]
			\end{enumerate}
			
			\item Soit \( u \) une fonction de \( L^2(\mathbb{R}) \) dont la transformée de Fourier \( L^2 \), encore notée \( \hat{u} \), est nulle (presque partout) en dehors d'un segment de \( \mathbb{R} \). Montrer que \( \hat{u} \) est intégrable et que pour presque tout \( x \in \mathbb{R} \),
			\[
			\hat{\hat{u}}(x) = u(-x),
			\]
			et en déduire qu'il existe \( v \in \mathcal{C}_0(\mathbb{R}) \) telle que \( u = v \) presque partout.
			
			\item On introduit l'espace
			\[
			B = \left\{ u \in L^2(\mathbb{R}) ; \, \hat{u} = 0 \text{ pp sur } \mathbb{R} \setminus [-\pi, \pi] \right\}.
			\]
			Montrer que \( B \) est un sous-espace fermé de \( L^2(\mathbb{R}) \), sur lequel \( \| \cdot \|_\infty \leq \| \cdot \|_2 \).
			
			\item On posera \( \text{sinc}(t) = \frac{\sin(t)}{t} \) et pour \( n \in \mathbb{Z} \),
			\[
			s_n(x) = \sqrt{2\pi} \text{sinc}(\pi(x-n)).
			\]
			Montrer que la famille \( (s_n)_{n \in \mathbb{Z}} \) forme une base hilbertienne de \( B \).
			
			\item Montrer que pour tout \( u \in B \) on a
			\[
			u = \sum_{n \in \mathbb{Z}} f(n) s_n
			\]
			dans \( L^2(\mathbb{R}) \), c'est-à-dire avec convergence dans \( L^2 \) de la série, et que si on note encore \( u \) le représentant continu, on a pour tout \( x \in \mathbb{R} \)
			\[
			u(x) = \sum_{n \in \mathbb{Z}} f(n) s_n(x)
			\]
			avec convergence uniforme de la série sur \( \mathbb{R} \).
		\end{enumerate}
	\end{exercise}
	
	\begin{proof}
		\begin{enumerate}
			\item \begin{enumerate}
				\item Comme $\hat{f}$ est à support compact, pour tout $n\in\mathbb{N}$, $|\hat{f}|=o(\frac{1}{|x^n|})$ en $|x|\rightarrow \infty$, donc $f\in\mathcal{C}^\infty$.\\
				En particulier, $\hat{f}\in L¹$ donc la formule d'inversion de Fourier donne 
				\[\forall t \in\mathbb{R}, f(t)=\frac{1}{2\pi}\int_{[-\pi,\pi]}\hat{f}(x)e^{ixt}dx\]
				\item \textbf{Heuristique :}
				Sur $[-\pi, \pi]$, $\hat{f}$ peut être développée en série de Fourier. Les coefficients sont :
				$c_k = \frac{1}{2\pi} \int_{-\pi}^\pi \hat{f}(x)e^{-ikx} dx$. D'après la formule d'inversion en $t=k$, on voit que $c_k = \frac{1}{\sqrt{2\pi}} f(-k)$.
				Le développement est $\hat{f}(x) = \sum \frac{1}{\sqrt{2\pi}} f(-k) e^{ikx}$. En changeant $k$ en $-k$, on obtient la formule de l'énoncé. 
				En injectant cette somme dans l'intégrale d'inversion :
				\[ f(t) = \frac{1}{\sqrt{2\pi}} \int_{-\pi}^\pi \left( \sqrt{2\pi} \sum_{k \in \mathbb{Z}} f(k) e^{-ikx} \right) e^{ixt} dx = \sum_{k \in \mathbb{Z}} f(k) \int_{-\pi}^\pi e^{ix(t-k)} dx \]
				L'intégrale vaut $\left[ \frac{e^{ix(t-k)}}{i(t-k)} \right]_{-\pi}^\pi = \frac{2 \sin(\pi(t-k))}{t-k}$. D'où le résultat.
			\end{enumerate}
				
			\item Si $\hat{u} \in L^2(\mathbb{R})$ est à support compact $K$, alors par l'inégalité de Cauchy-Schwarz :
			\[ \int_K |\hat{u}(x)| dx \leq \sqrt{\text{mes}(K)} \left( \int_K |\hat{u}(x)|^2 dx \right)^{1/2} < \infty \]
			Donc $\hat{u} \in L^1(\mathbb{R})$. Puisque $\hat{u} \in L^1 \cap L^2$, la formule d'inversion $L^1$ s'applique presque partout. On applique le résultat de la question 1 pour $f=u$, et on définit $v$ comme la transformée de Fourier inverse de $\hat{u}$.
				
			\item Posons $\Psi:L^{2}\rightarrow L^{2}$ l'application définie par $\Psi:u\rightarrow\widehat{u}\mathbf{1}_{[-\pi,\pi]}$ qui est une application linéaire continue par propriétés de la transformée de Fourier. On a donc $B=\ker\Psi$ qui est donc fermé.\\
			$B$ est l'image réciproque du sous-espace fermé $\{ \phi \in L^2 \mid \phi = 0 \text{ sur } \mathbb{R} \setminus [-\pi, \pi] \}$ par la transformée de Fourier. Comme cette dernière est une isométrie de $L^2$ (théorème de Plancherel), $B$ est fermé. \\
			Pour l'inégalité, si $u \in B$, $u(x) = \frac{1}{\sqrt{2\pi}} \int_{-\pi}^\pi \hat{u}(\xi)e^{ix\xi} d\xi$.
			Par Cauchy-Schwarz : $|u(x)| \leq \frac{1}{\sqrt{2\pi}} \sqrt{2\pi} \|\hat{u}\|_2 = \|u\|_2$. Donc $\|u\|_\infty \leq \|u\|_2$.
				
			\item Posons pour tout $n\in\mathbb{Z}$,
			\[f_n(t)=e^{int}\mathbf{1}_{[-\pi,\pi]}(t),\text{ pour tout }t\in\mathbb{R}\]
			Alors pour $x\in\mathbb{R}$,
			\[\widehat{f_n(x)}=\int_\mathbb{R}e^{i(n-x)t}\mathbf{1}_{[-\pi,\pi]}(t)dt=2\pi s_n(x)\]
			On en déduit ainsi $\widehat{s_n(x)}=e^{-inx}\mathbf{1}_{[-\pi,\pi]}(x)$ pp.\\
			Par Plancherel, pour $n,m\in\mathbb{Z}$ distincts :
			\[\langle s_n,s_m\rangle=\frac{1}{2\pi}\langle \widehat{s_n}\widehat{s_m}\rangle=\frac{1}{2\pi}\int_{[-\pi,\pi]}e^{-i(n-m)x}dx=\delta_{n,m}\]
			Donc $(s_n)_{n\in\mathbb{Z}}$ est une famille orthonormée.\\
			Soit $u\in B$ telle que $\forall n\in\mathbb{Z}, \langle u,s_n\rangle=0$. Alors par Plancherel $\forall n\in\mathbb{Z}, \langle \widehat{u},\widehat{s_n}\rangle=0$, c'est à dire
			\[\forall n\in\mathbb{Z}, \int_{[-\pi,\pi]}\widehat{u}(x)e^{-inx}dx=0\]
			En considérant $\tilde{\widehat{u}}$ étendue par $2\pi$ périodicité, on a $\forall n\in\mathbb{Z}, \tilde{u}(n)=0$, donc $\tilde{u}=0$ pp et donc $u=0$ pp sur $[\pi,\pi]$. Ainsi la famille $(s_n)_{n\in\mathbb{Z}}$ est dense dans $L^{2}$. C'est donc une base hilbertienne de $B$.
				
			\item Comme $(s_n)$ est une base hilbertienne de $B$, tout $u \in B$ s'écrit $u = \sum \langle u, s_n \rangle s_n$ avec convergence dans $L^2$. 
			Le coefficient est $\langle u, s_n \rangle = \int u(x) s_n(x) dx$. Par Plancherel, c'est aussi :
			\[\langle \hat{u}, \hat{s}_n \rangle = \frac{1}{2\pi}\int_{-\pi}^{\pi}\widehat{u}(x)e^{inx}dx= u(n)\]
			En utilisant le résultat de la première question.\\
			Enfin, la convergence uniforme découle de l'inégalité sur les normes obtenue à la question 3 :
			\[ \|u - \sum_{n=-N}^N u(n) s_n \|_\infty \leq \|u - \sum_{n=-N}^N u(n) s_n \|_2 \xrightarrow[N \to \infty]{} 0 \]
			\item (Lien avec le théorème de Shannon en physique) En physique, le théorème de Shannon dit que pour ne pas perdre d'information lors de l'échantillonage d'un signal, il faut échantillonner à une fréquence supérieure à deux fois la fréquence maximale du signal. Dans l'exercice, la fréquence maximale du signal est $\pi$ puisque sa transformée de Fourier (ses fréquences) sont nulles au-delà. On doit donc échantillonner à une fréquence d'au moins $2\pi$, donc une période $T=\frac{2\pi}{2\pi}=1$ pour ne pas perdre d'information (c'est bien le cas ici). Lorsque la condition n'est pas respectée, on perd de l'information et on parle de repliement de spectre.
			\centering
			\includegraphics[width=0.8\textwidth]{img/shannon.png}			

		\end{enumerate}
	\end{proof}
	
	\setcounter{section}{9}
	\section{Equations différentielles}
	\setcounter{exercise}{0}
	\begin{exercise}
		Résoudre les équations différentielles suivantes :
		\begin{enumerate}
			\item $y'(t) = t^2y(t) + t^2$, avec $y(0) = 1$.
			\item $y''(t) + y'(t) + y(t) = 0$, avec $y(0) = 0, y'(0) = 1$.
			\item $y'(t) = A y(t)$, avec $A = \begin{pmatrix} 2 & 1 & 0 \\ 0 & 2 & 1 \\ 0 & 0 & 2 \end{pmatrix}$ et $y(0) = \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}$.
			\item $y'(t) + e^{t-y(t)} = 0$, avec $y(0) = 0$.
		\end{enumerate}
	\end{exercise}
	
	\begin{proof}
		\begin{enumerate}
			\item L'équation est $y'(t) - t^2y(t) = t^2$. C'est une équation linéaire du premier ordre.
			\begin{itemize}
				\item {Solution homogène :} $y_h'(t) = t^2 y_h(t)$. Une primitive de $t^2$ est $\frac{t^3}{3}$. Donc $y_h(t) = C e^{t^3/3}$.
				\item {Solution particulière :} On remarque la solution constante $y_p(t) = -1$ car $y_p' = 0$ et $t^2(-1) + t^2 = 0$.
				\item {Solution générale :} $y(t) = C e^{t^3/3} - 1$.
				\item {Condition initiale :} $y(0) = 1 \implies C e^{0} - 1 = 1 \implies C = 2$.
			\end{itemize}
			La solution est \textbf{$y(t) = 2e^{t^3/3} - 1$}.
			\item L'équation caractéristique est $r^2 + r + 1 = 0$. Le discriminant est $\Delta = 1^2 - 4 = -3 = (i\sqrt{3})^2$.
			Les racines sont $r = -\frac{1}{2} \pm i\frac{\sqrt{3}}{2}$.
			La forme générale est $y(t) = e^{-t/2} \left[ A \cos\left(\frac{\sqrt{3}}{2}t\right) + B \sin\left(\frac{\sqrt{3}}{2}t\right) \right]$.
			\begin{itemize}
				\item $y(0) = 0 \implies A = 0$. Donc $y(t) = B e^{-t/2} \sin\left(\frac{\sqrt{3}}{2}t\right)$.
				\item $y'(t) = B e^{-t/2} \left[ -\frac{1}{2}\sin\left(\frac{\sqrt{3}}{2}t\right) + \frac{\sqrt{3}}{2}\cos\left(\frac{\sqrt{3}}{2}t\right) \right]$.
				\item $y'(0) = 1 \implies B \cdot \frac{\sqrt{3}}{2} = 1 \implies B = \frac{2}{\sqrt{3}}$.
			\end{itemize}
			La solution est \textbf{$y(t) = \frac{2}{\sqrt{3}} e^{-t/2} \sin\left(\frac{\sqrt{3}}{2}t\right)$}.
			
			\item Le système est $y'(t) = Ay(t)$. La solution est $y(t) = e^{tA}y(0)$.
			On décompose $A = 2I + N$ avec $N = \begin{pmatrix} 0 & 1 & 0 \\ 0 & 0 & 1 \\ 0 & 0 & 0 \end{pmatrix}$. Comme $2I$ et $N$ commutent : $e^{tA} = e^{2tI}e^{tN} = e^{2t} e^{tN}$.
			$N^2 = \begin{pmatrix} 0 & 0 & 1 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{pmatrix}$ et $N^3 = 0$.
			Donc $e^{tN} = I + tN + \frac{t^2}{2}N^2 = \begin{pmatrix} 1 & t & t^2/2 \\ 0 & 1 & t \\ 0 & 0 & 1 \end{pmatrix}$.
			Le vecteur solution est $y(t) = e^{2t} \begin{pmatrix} 1 & t & t^2/2 \\ 0 & 1 & t \\ 0 & 0 & 1 \end{pmatrix} \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}$.
			D'où \textbf{$y(t) = e^{2t} \begin{pmatrix} 1 + t + \frac{t^2}{2} \\ 1 + t \\ 1 \end{pmatrix}$}.
			
			\item L'équation est $y'(t) = -e^t e^{-y(t)}$, ce qui s'écrit $e^{y(t)} y'(t) = -e^t$.
			En intégrant par rapport à $t$ : $\int e^{y} dy = \int -e^t dt$.
			On obtient $e^{y(t)} = -e^t + C$.
			Condition initiale : $y(0) = 0 \implies e^0 = -e^0 + C \implies 1 = -1 + C \implies C = 2$.
			Ainsi $e^{y(t)} = 2 - e^t$. En passant au logarithme :
			La solution est \textbf{$y(t) = \ln(2 - e^t)$}, définie pour $t < \ln(2)$.
		\end{enumerate}
	\end{proof}
	
	
	\setcounter{exercise}{2}
	\begin{exercise}
		Résoudre le problème différentiel suivant sur $\mathbb{R}$\\
		\[2x²y'=1-y²\]
	\end{exercise}
	
	\begin{proof}
		\begin{itemize}
			\item On travaille sur $I\subset \mathbb{R}$. Posons $f(x,y)=\frac{1-y²}{2x²}$. $f$ est :\\
			\begin{itemize}
				\item continue sur $I\times \mathbb{R}$
				\item $\mathcal{C}¹$ en $y$ donc localement lipschitzienne en $y$
			\end{itemize}
			Par le théorème de Cauchy Lipschitz, pour tout $(x_0,y_0)$, il existe une unique solution définie sur $I$.
		\end{itemize}
	\end{proof}
	
	\setcounter{exercise}{5}
	\begin{exercise}
		\textbf{Exercice 6.} Soit une fonction continue $A : \mathbb{R} \to M_n(\mathbb{R})$. On note $(y_1,\dots,y_n)$ une base de solutions de l’équation différentielle
		\[
		y'(t)=A(t)y(t), \qquad t\in\mathbb{R}.
		\]
		On notera aussi $M(t)$ la matrice $(y_1(t),\dots,y_n(t))$ dans la base canonique de $\mathbb{R}^n$.
		\begin{enumerate}
			\item Calculer le wronskien $W(t)=\det M(t)$, pour tout $t\in\mathbb{R}$.
			\item On suppose maintenant que $\|A(\cdot)\|$ est intégrable sur $\mathbb{R}_+$.
			\begin{enumerate}
				\item Montrer que toute solution $y$ admet une limite en $+\infty$.
				\item Soit $\theta$ l’application qui à $y_0\in\mathbb{R}^n$ associe la limite en $+\infty$ de la solution $y$ telle que $y(0)=y_0$. Montrer que $\theta$ est un isomorphisme de $\mathbb{R}^n$ sur $\mathbb{R}^n$.
			\end{enumerate}
		\end{enumerate}
		\end{exercise}
		
		\begin{proof}
		
		
		1. La matrice fondamentale $M(t)$ vérifie
		\[
		M'(t)=A(t)M(t).
		\]
		On pose $W(t)=\det M(t)$. Par la formule de dérivation du déterminant,
		\[
		W'(t)=\operatorname{tr}(A(t))\,W(t).
		\]
		On obtient donc une équation différentielle scalaire :
		\[
		W'(t)=\operatorname{tr}(A(t))\,W(t).
		\]
		En intégrant,
		\[
		W(t)=W(0)\exp\!\left(\int_0^t \operatorname{tr}(A(s))\,ds\right).
		\]
		En particulier, si $(y_1,\dots,y_n)$ est une base de solutions, alors $W(0)\neq 0$, donc
		\[
		W(t)\neq 0 \quad \text{pour tout } t\in\mathbb{R}.
		\]
		
		2.a) Soit $y$ une solution. Elle vérifie
		\[
		y(t)=y(0)+\int_0^t A(s)y(s)\,ds.
		\]
		Pour $t\ge s\ge 0$,
		\[
		y(t)-y(s)=\int_s^t A(\tau)y(\tau)\,d\tau.
		\]
		On en déduit
		\[
		\|y(t)-y(s)\|
		\le
		\int_s^t \|A(\tau)\|\,\|y(\tau)\|\,d\tau.
		\]
		Par ailleurs on a également,
		\[\|y(t)\|\leq \|y(0)\| + \int_{0}^{t}\|A(s)y(s)\|ds\]
		Donc en appliquant le lemme de Gronwall pour $\|A(\cdot)\|$ positive et $\|y(\cdot)\|$ continue, pour $t\ge 0$,
		\[
		\|y(t)\|
		\le
		\|y(0)\|\exp\!\left(\int_0^t \|A(\sigma)\|\,d\sigma\right).
		\]
		Comme $\|A(\cdot)\|$ est intégrable sur $\mathbb{R}_+$, la quantité
		\[
		C=\exp\!\left(\int_0^{+\infty} \|A(\sigma)\|\,d\sigma\right)
		\]
		est finie, et donc
		\[
		\|y(t)\|\le C\|y(0)\| \quad \text{pour tout } t\ge 0.
		\]
		Ainsi $y$ est bornée sur $\mathbb{R}_+$.
		
		Dès lors,
		\[
		\|y(t)-y(s)\|
		\le
		C\|y(0)\|\int_s^t \|A(\tau)\|\,d\tau.
		\]
		Comme $\|A\|$ est intégrable sur $\mathbb{R}_+$, le membre de droite tend vers $0$ lorsque $s,t\to+\infty$.  
		
		Donc $y(t)$ est de Cauchy lorsque $t\to+\infty$, et comme $\mathbb{R}^n$ est complet, $y(t)$ admet une limite lorsque $t\to+\infty$.\\
		
		2.b) On définit
		\[
		\theta : \mathbb{R}^n \to \mathbb{R}^n,
		\qquad
		\theta(y_0)=\lim_{t\to+\infty} y(t),
		\]
		où $y$ est l’unique solution telle que $y(0)=y_0$.
		
		D'après la question précédente, $\theta$ est bien définie. Elle est linéaire car l’équation différentielle est linéaire.
		
		Montrons qu’elle est injective.  
		
		Si $\theta(y_0)=0$, alors $y(t)\to 0$ lorsque $t\to+\infty$.  
		On écrit, pour $t\ge 0$,
		\[
		y(t)=y(T)-\int_t^T A(s)y(s)\,ds.
		\]
		En faisant tendre $T\to+\infty$ et en utilisant que $y(T)\to 0$, on obtient
		\[
		y(t)=-\int_t^{+\infty} A(s)y(s)\,ds.
		\]
		On en déduit
		\[
		\|y(t)\|
		\le
		\int_t^{+\infty} \|A(s)\|\,\|y(s)\|\,ds.
		\]
		En posant
		\[
		m(t)=\sup_{u\ge t}\|y(u)\|,
		\]
		qui est bien défini car $\|y(\cdot)\|$ est continue et $y(t)\rightarrow 0$ en $+\infty$, on obtient
		\[
		m(t)\le m(t)\int_t^{+\infty}\|A(s)\|\,ds.
		\]
		Et comme $\|A(\cdot)\|$ est intégrable, on a pour $t$ assez grand,
		\[
		\int_t^{+\infty}\|A(s)\|\,ds<1,
		\]
		donc nécessairement $m(t)=0$. Ainsi $y(t)=0$ pour $t$ assez grand, puis par unicité des solutions, $y\equiv 0$. Donc $y_0=0$.
		
		Ainsi $\theta$ est injective.  
		
		Comme $\theta$ est linéaire entre deux espaces vectoriels de même dimension finie $n$, elle est bijective.  
		
		Donc $\theta$ est un isomorphisme de $\mathbb{R}^n$ sur $\mathbb{R}^n$.
		
	
	\end{proof}
	
	
\end{document}
